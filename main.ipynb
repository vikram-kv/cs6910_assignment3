{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS6910 Assignment 3 (RNN Frameworks for transliteration) - Without attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries for the notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# set the device to 'cuda' if available\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# define the source and target languages\n",
    "TARGET = 'hin'\n",
    "SOURCE = 'eng'\n",
    "# define the special tokens that stand for start of seq, end of seq, \n",
    "# an unknown symbol.\n",
    "SOS_SYM = '@'\n",
    "EOS_SYM = '$'\n",
    "UNK_SYM = '!'\n",
    "# define a special token for padding - this helps with batch processing \n",
    "PAD_SYM = '%'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Functions and Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load the 'cat' (= train/val/test) data of language 'lang'\n",
    "def load_data(lang, cat):\n",
    "    fcontents = open(f'aksharantar_sampled/{lang}/{lang}_{cat}.csv','r', encoding='utf-8').readlines()\n",
    "    pairs = [tuple(l.strip().split(',')) for l in fcontents]\n",
    "    x_data, y_data = list(map(list,zip(*pairs)))\n",
    "    return x_data, y_data\n",
    "\n",
    "# class for a language with useful functions.\n",
    "class Language:\n",
    "    def __init__(self, name):\n",
    "        self.lname = name\n",
    "    \n",
    "    # function to create the vocabulary(set of tokens) using the words in 'data'\n",
    "    # here, a token is either a special token or a lang character\n",
    "    def create_vocabulary(self, *data):\n",
    "        symbols = set()\n",
    "        for wd in data:\n",
    "            for c in wd:\n",
    "                symbols.add(c)\n",
    "        self.symbols = symbols\n",
    "    \n",
    "    # function to generate the index2sym (a number to a token) and \n",
    "    # sym2index (a token to a number) mappings using the vocabulary\n",
    "    def generate_mappings(self):\n",
    "        self.index2sym = {0: SOS_SYM, 1 : EOS_SYM, 2 : UNK_SYM, 3 : PAD_SYM}\n",
    "        self.sym2index = {SOS_SYM : 0, EOS_SYM : 1, UNK_SYM : 2, PAD_SYM : 3}\n",
    "        self.symbols = list(self.symbols)\n",
    "        self.symbols.sort()\n",
    "\n",
    "        for i, sym in enumerate(self.symbols):\n",
    "            self.sym2index[sym] = i + 4\n",
    "            self.index2sym[i+4] = sym\n",
    "        \n",
    "        self.num_tokens = len(self.index2sym.keys())\n",
    "    \n",
    "    # function to tokenize a word and convert all the tokens to\n",
    "    # their corr. numbers using sym2index\n",
    "    def convert_to_numbers(self, word):\n",
    "        enc = [self.sym2index[SOS_SYM]]\n",
    "        for ch in word:\n",
    "            if ch in self.sym2index.keys():\n",
    "                enc.append(self.sym2index[ch])\n",
    "            else:\n",
    "                enc.append(self.sym2index[UNK_SYM])\n",
    "        enc.append(self.sym2index[EOS_SYM])\n",
    "        return enc\n",
    "    \n",
    "    # convert a list of predictions (each prediction is a list of numbers)\n",
    "    # to the corresponding list of words using index2sym\n",
    "    # pred should be numpy array of shape (number_of_words, max_word_length)\n",
    "    # tokens after EOS_SYM are discarded\n",
    "    def convert_to_words(self, preds):\n",
    "        num = preds.shape[0]\n",
    "        words = [] \n",
    "        for i in range(num):\n",
    "            wd = ''\n",
    "            for idx in preds[i][1:]:\n",
    "                ch = self.index2sym[idx]\n",
    "                if ch != EOS_SYM:\n",
    "                    wd += ch\n",
    "            words.append(wd)\n",
    "        return words\n",
    "\n",
    "    # get the number assigned to a token\n",
    "    def get_index(self, sym):\n",
    "        return self.sym2index[sym]\n",
    "    \n",
    "    # get the number of tokens in the vocabulary\n",
    "    def get_size(self):\n",
    "        return self.num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples = 51200\n",
      "Number of valid samples = 4096\n",
      "Number of test samples = 4096\n"
     ]
    }
   ],
   "source": [
    "# load all the available data and print sample counts for each set\n",
    "x_train, y_train = load_data(TARGET, 'train')\n",
    "x_valid, y_valid = load_data(TARGET, 'valid')\n",
    "x_test, y_test = load_data(TARGET, 'test')\n",
    "\n",
    "print(f'Number of train samples = {len(x_train)}')\n",
    "print(f'Number of valid samples = {len(x_valid)}')\n",
    "print(f'Number of test samples = {len(x_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Vocabulary Size = 26\n",
      "Source Vocabulary = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Source Mapping {0: '@', 1: '$', 2: '!', 3: '%', 4: 'a', 5: 'b', 6: 'c', 7: 'd', 8: 'e', 9: 'f', 10: 'g', 11: 'h', 12: 'i', 13: 'j', 14: 'k', 15: 'l', 16: 'm', 17: 'n', 18: 'o', 19: 'p', 20: 'q', 21: 'r', 22: 's', 23: 't', 24: 'u', 25: 'v', 26: 'w', 27: 'x', 28: 'y', 29: 'z'}\n",
      "Target Vocabulary Size = 64\n",
      "Target Vocabulary = ['ँ', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ऑ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'ळ', 'व', 'श', 'ष', 'स', 'ह', '़', 'ऽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॅ', 'े', 'ै', 'ॉ', 'ो', 'ौ', '्']\n",
      "Target Mapping {0: '@', 1: '$', 2: '!', 3: '%', 4: 'ँ', 5: 'ं', 6: 'ः', 7: 'अ', 8: 'आ', 9: 'इ', 10: 'ई', 11: 'उ', 12: 'ऊ', 13: 'ऋ', 14: 'ए', 15: 'ऐ', 16: 'ऑ', 17: 'ओ', 18: 'औ', 19: 'क', 20: 'ख', 21: 'ग', 22: 'घ', 23: 'ङ', 24: 'च', 25: 'छ', 26: 'ज', 27: 'झ', 28: 'ञ', 29: 'ट', 30: 'ठ', 31: 'ड', 32: 'ढ', 33: 'ण', 34: 'त', 35: 'थ', 36: 'द', 37: 'ध', 38: 'न', 39: 'प', 40: 'फ', 41: 'ब', 42: 'भ', 43: 'म', 44: 'य', 45: 'र', 46: 'ल', 47: 'ळ', 48: 'व', 49: 'श', 50: 'ष', 51: 'स', 52: 'ह', 53: '़', 54: 'ऽ', 55: 'ा', 56: 'ि', 57: 'ी', 58: 'ु', 59: 'ू', 60: 'ृ', 61: 'ॅ', 62: 'े', 63: 'ै', 64: 'ॉ', 65: 'ो', 66: 'ौ', 67: '्'}\n"
     ]
    }
   ],
   "source": [
    "# create language objects for storing vocabulary, index2sym and sym2index\n",
    "SRC_LANG = Language(SOURCE)\n",
    "TAR_LANG = Language(TARGET)\n",
    "\n",
    "# creating vocabulary using train data only\n",
    "SRC_LANG.create_vocabulary(*(x_train))\n",
    "TAR_LANG.create_vocabulary(*(y_train))\n",
    "\n",
    "# otherwise, use unicode characters (assigned codepoints) in the script's range\n",
    "# src_lang.create_vocabulary_range()\n",
    "# tar_lang.create_vocabulary_range()\n",
    "\n",
    "# generate mappings from characters to numbers and vice versa\n",
    "SRC_LANG.generate_mappings()\n",
    "TAR_LANG.generate_mappings()\n",
    "\n",
    "# print the source and target vocabularies\n",
    "print(f'Source Vocabulary Size = {len(SRC_LANG.symbols)}')\n",
    "print(f'Source Vocabulary = {SRC_LANG.symbols}')\n",
    "print(f'Source Mapping {SRC_LANG.index2sym}')\n",
    "print(f'Target Vocabulary Size = {len(TAR_LANG.symbols)}')\n",
    "print(f'Target Vocabulary = {TAR_LANG.symbols}')\n",
    "print(f'Target Mapping {TAR_LANG.index2sym}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransliterateDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data, src_lang : Language, tar_lang : Language):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        self.src_lang = src_lang\n",
    "        self.tar_lang = tar_lang\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_enc, y_enc = self.x_data[idx], self.y_data[idx]\n",
    "        x_enc = self.src_lang.convert_to_numbers(x_enc)\n",
    "        y_enc = self.tar_lang.convert_to_numbers(y_enc) \n",
    "        return torch.tensor(x_enc, dtype=int), torch.tensor(y_enc,dtype=int), self.y_data[idx]\n",
    "\n",
    "class CollationFunction:\n",
    "    def __init__(self, src_lang : Language, tar_lang : Language):\n",
    "        self.src_lang = src_lang\n",
    "        self.tar_lang = tar_lang\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        # sorting is to save encoder computation. \n",
    "        # reasoning : https://stackoverflow.com/questions/51030782/why-do-we-pack-the-sequences-in-pytorch\n",
    "        batch.sort(key = lambda x : len(x[0]), reverse=True)\n",
    "        src, tar, tar_words = zip(*batch)\n",
    "        src_lens = torch.tensor([len(x) for x in src], dtype=int)\n",
    "        src = nn.utils.rnn.pad_sequence(list(src), batch_first=True, padding_value=self.src_lang.get_index(PAD_SYM))\n",
    "        tar = nn.utils.rnn.pad_sequence(list(tar), batch_first=True, padding_value=self.tar_lang.get_index(PAD_SYM))\n",
    "        return src, tar, src_lens, tar_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderNet(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_layers, hid_size, cell_type, \n",
    "                 bidirect=False, dropout=0):\n",
    "        super(EncoderNet, self).__init__()\n",
    "        self.hidden_size = hid_size\n",
    "        self.embed_size = embed_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # we create the required architecture using the received parameters\n",
    "        kwargs = {'input_size':embed_size, 'hidden_size':hid_size, 'num_layers':num_layers, \n",
    "                 'bidirectional':bidirect, 'batch_first':True}\n",
    "        if num_layers > 1:\n",
    "            kwargs['dropout'] = dropout\n",
    "        if cell_type == 'RNN':\n",
    "            self.network = nn.RNN(**kwargs)\n",
    "        elif cell_type == 'LSTM':\n",
    "            self.network = nn.LSTM(**kwargs)\n",
    "        else:\n",
    "            self.network = nn.GRU(**kwargs)\n",
    "        \n",
    "        self.cell_type = cell_type\n",
    "        self.bidirect = bidirect\n",
    "\n",
    "        # for combining the final layer's forward and reverse directions' final hidden state\n",
    "        if (self.bidirect):\n",
    "            self.combine_forward_backward = nn.Linear(2 * hid_size, hid_size)\n",
    "\n",
    "    def forward(self, batch_x, batch_lens):\n",
    "        batch_x = self.embedding(batch_x)\n",
    "        batch_x = self.dropout(batch_x)\n",
    "        packed_batch_x = nn.utils.rnn.pack_padded_sequence(batch_x, lengths=batch_lens, batch_first=True, \n",
    "                                                           enforce_sorted=True)\n",
    "        if self.cell_type == 'LSTM':\n",
    "            packed_outputs, (hidden_outputs, _) = self.network(packed_batch_x,)\n",
    "        else:\n",
    "            packed_outputs, hidden_outputs = self.network(packed_batch_x)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs, batch_first=True)\n",
    "        if self.bidirect:\n",
    "            # remember 2nd dim in hidden_outputs; so, we have to concatenate forward and backward\n",
    "            # final hidden states along **1st dimension**\n",
    "            concat_hidden_state = torch.cat((hidden_outputs[-2,:,:], hidden_outputs[-1,:,:]), dim=1)\n",
    "            hidden_state = self.combine_forward_backward(concat_hidden_state)\n",
    "            hidden_state = torch.tanh(hidden_state)\n",
    "        else:\n",
    "            hidden_state = hidden_outputs[-1, :, :]\n",
    "        # hidden_state = (batch_size, hid_size); outputs = (batch_size, max_seq_len_batch, D * hid_size)\n",
    "        # d = 2 if bidirectional; else d = 1\n",
    "        return outputs, hidden_state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderNet(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_layers, hid_size, cell_type, \n",
    "                 dropout=0):\n",
    "        super(DecoderNet, self).__init__()\n",
    "        self.hidden_size = hid_size\n",
    "        self.embed_size = embed_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.num_layers = num_layers\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "       # we create the required architecture using the received parameters\n",
    "        kwargs = {'input_size':embed_size, 'hidden_size':hid_size, 'num_layers':num_layers, \n",
    "                 'batch_first':True}\n",
    "        if num_layers > 1:\n",
    "            kwargs['dropout'] = dropout\n",
    "        if cell_type == 'RNN':\n",
    "            self.network = nn.RNN(**kwargs)\n",
    "        elif cell_type == 'LSTM':\n",
    "            self.network = nn.LSTM(**kwargs)\n",
    "        else:\n",
    "            self.network = nn.GRU(**kwargs)\n",
    "\n",
    "        self.cell_type = cell_type\n",
    "        self.out_layer = nn.Linear(hid_size, vocab_size)\n",
    "\n",
    "    # will always go 1 step forward in time (seqlen = L = 1)\n",
    "    # previous decoder state shape = [num_layers, batch_size, hid_size]\n",
    "    def forward(self, batch_y, prev_decoder_state):\n",
    "        batch_y = batch_y.unsqueeze(1) # batch_size is first dim\n",
    "        batch_y = self.embedding(batch_y)\n",
    "        batch_y = self.dropout(batch_y)\n",
    "        if self.cell_type == 'LSTM':\n",
    "            decoder_hidden_state, decoder_cell_state = prev_decoder_state\n",
    "            outputs, (decoder_hidden_state, decoder_cell_state) = self.network(batch_y, (decoder_hidden_state, decoder_cell_state))\n",
    "        else:\n",
    "            outputs, decoder_hidden_state = self.network(batch_y, prev_decoder_state)\n",
    "        \n",
    "        outputs = outputs.squeeze(1) # remove seqlen dimension\n",
    "        logits = self.out_layer(outputs)\n",
    "        if self.cell_type == 'LSTM':\n",
    "            return logits, (decoder_hidden_state, decoder_cell_state)\n",
    "        else:\n",
    "            return logits, decoder_hidden_state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq(Encoder-Decoder) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore changing teacher forcing ratio to something epoch-based as sir suggested\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder :EncoderNet, decoder : DecoderNet, src_lang, tar_lang) -> None:\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.enc_model = encoder\n",
    "        self.dec_model = decoder\n",
    "        self.src_lang = src_lang\n",
    "        self.tar_lang = tar_lang\n",
    "        self.cell_type = self.dec_model.cell_type\n",
    "    \n",
    "    def forward(self, batch_X, batch_Y, X_lens, tf_ratio):\n",
    "        batch_size = batch_X.size(0)\n",
    "        _, final_enc_hidden_state = self.enc_model(batch_X, X_lens)\n",
    "        num_dec_layers = self.dec_model.num_layers\n",
    "        decoder_state = torch.stack([final_enc_hidden_state for _ in range(num_dec_layers)], dim=0)\n",
    "        # we will feed the encoder output into each decoder layer's initial hidden state\n",
    "        # hidden_dec = (num_layers, batch_size, hid_size)\n",
    "\n",
    "        tarlength = batch_Y.size(1)\n",
    "        outlogits = torch.zeros(batch_size, tarlength, self.dec_model.vocab_size).to(device)\n",
    "        preds = torch.zeros(batch_size, tarlength).to(device)\n",
    "        dec_input = batch_Y[:,0]\n",
    "\n",
    "        if (self.cell_type == 'LSTM'):\n",
    "            init_dec_cell_state = torch.stack([torch.zeros_like(final_enc_hidden_state) for _ in range(num_dec_layers)], dim=0).to(device)\n",
    "            decoder_state = (decoder_state, init_dec_cell_state)\n",
    "        \n",
    "        for tstep in range(1, tarlength):\n",
    "            curlogits, decoder_state = self.dec_model(dec_input, decoder_state)\n",
    "            tf_force_input = batch_Y[:, tstep]\n",
    "            pred = torch.argmax(curlogits, dim=1).to(device)\n",
    "            dec_input = pred\n",
    "            if tf_ratio != None:\n",
    "                rand_num = torch.randn(1)[0]\n",
    "                if rand_num <= tf_ratio:\n",
    "                    dec_input = tf_force_input\n",
    "            outlogits[:, tstep, :] = curlogits \n",
    "            preds[:, tstep] = pred\n",
    "\n",
    "        return outlogits, preds "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Evaluation/Inference Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner():\n",
    "    def __init__(self, src_lang : Language, tar_lang : Language, common_embed_size, num_enc_layers, num_dec_layers, \n",
    "                 common_hidden_size, common_cell_type, enc_bidirect, dropout, opt_name='Adam',\n",
    "                 learning_rate=1e-3):\n",
    "        self.src_lang = src_lang\n",
    "        self.tar_lang = tar_lang\n",
    "        # create all the sub-networks and the main model\n",
    "        self.encoder = EncoderNet(vocab_size=src_lang.get_size(), embed_size=common_embed_size,\n",
    "                             num_layers=num_enc_layers, hid_size=common_hidden_size,\n",
    "                             cell_type= common_cell_type, bidirect=enc_bidirect, dropout=dropout)\n",
    "        self.decoder = DecoderNet(vocab_size=tar_lang.get_size(), embed_size=common_embed_size,\n",
    "                             num_layers=num_dec_layers, hid_size=common_hidden_size,\n",
    "                             cell_type=common_cell_type, dropout=dropout)\n",
    "        self.model = EncoderDecoder(encoder=self.encoder, decoder=self.decoder, src_lang=src_lang, \n",
    "                                    tar_lang=tar_lang)\n",
    "        # move model to the torch device\n",
    "        self.model.to(device)\n",
    "        # for reproducibility - seed everything with 42\n",
    "        torch.manual_seed(42); torch.cuda.manual_seed(42); np.random.seed(42); random.seed(42)\n",
    "        self.model.apply(self.init_weights) # initialize model weights\n",
    "        self.trainLoader, self.validLoader, self.testLoader = None, None, None\n",
    "        self.optimizer = None\n",
    "        self.loss_criterion = nn.CrossEntropyLoss(ignore_index=tar_lang.sym2index[PAD_SYM])\n",
    "        if opt_name == 'Adam':\n",
    "            self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.normal_(param.data, mean=0, std=0.05)\n",
    "            else:\n",
    "                nn.init.constant_(param.data, 0)\n",
    "    \n",
    "    def generate_data_loaders(self, data_X, data_y, batch_size):\n",
    "        dataset = TransliterateDataset(data_X, data_y, src_lang=SRC_LANG, tar_lang=TAR_LANG)\n",
    "        dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                                collate_fn=CollationFunction(SRC_LANG, TAR_LANG))\n",
    "        return dataloader\n",
    "\n",
    "    def make_all_loaders(self, train_data, valid_data, test_data, batch_size):\n",
    "        train_X, train_y = train_data\n",
    "        valid_X, valid_y = valid_data\n",
    "        test_X, test_y = test_data\n",
    "\n",
    "        self.trainLoader = self.generate_data_loaders(train_X, train_y, batch_size)\n",
    "        self.validLoader = self.generate_data_loaders(valid_X, valid_y, batch_size)\n",
    "        self.testLoader = self.generate_data_loaders(test_X, test_y, batch_size)\n",
    "\n",
    "    def get_accuracy(self, pred_words, tar_words):\n",
    "        assert(len(pred_words) == len(tar_words))\n",
    "        count = 0\n",
    "        for i in range(len(pred_words)):\n",
    "            if pred_words[i] == tar_words[i]:\n",
    "                count += 1\n",
    "        return count / len(pred_words)\n",
    "\n",
    "    def train_one_epoch(self, epoch_number, tf_ratio=0.6):\n",
    "        assert(self.trainLoader != None); assert(self.optimizer != None)\n",
    "\n",
    "        # set model in training mode for autograd to be activated\n",
    "        self.model.train(); self.optimizer.zero_grad()\n",
    "        train_loss = 0.0\n",
    "        pred_words, true_words = [], []\n",
    "        with tqdm(self.trainLoader, unit='batch') as tqdmLoader:\n",
    "            for batch_X, batch_y, X_lens, y_words in tqdmLoader:\n",
    "                tqdmLoader.set_description(f'Epoch {epoch_number}')\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                \n",
    "                # get the logits, preds for the current batch\n",
    "                logits, preds = self.model(batch_X, batch_y, X_lens, tf_ratio=tf_ratio)\n",
    "                # ignore loss for the first time step\n",
    "                targets = batch_y[:, 1:]; logits = logits[:, 1:, :]\n",
    "                logits = logits.swapaxes(1, 2) # make class logits the second dimension as needed\n",
    "                loss = self.loss_criterion(logits, targets)\n",
    "                loss.backward()\n",
    "                self.optimizer.step(); self.optimizer.zero_grad()\n",
    "                train_loss += loss.item()\n",
    "                batch_pred_words = self.tar_lang.convert_to_words(preds.cpu().numpy())\n",
    "                tqdmLoader.set_postfix(loss=loss.item())\n",
    "                true_words += y_words\n",
    "                pred_words += batch_pred_words\n",
    "        train_loss /= len(self.trainLoader)\n",
    "        train_acc = self.get_accuracy(pred_words, true_words)\n",
    "        print(f'Train Loss = {train_loss}; Train Accuracy = {train_acc * 100}')\n",
    "        return pred_words, true_words # return train loss and accuracy\n",
    "\n",
    "    def evaluate(self, ):\n",
    "        assert(self.validLoader != None)\n",
    "\n",
    "    def inference(self, ):\n",
    "        pass\n",
    "    \n",
    "    def beam_search_inference(self, ):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing runner\n",
    "\n",
    "runner = Runner(SRC_LANG, TAR_LANG, 64, 1, 1, 256, 'LSTM', False, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.make_all_loaders((x_train, y_train), (x_valid, y_valid), (x_test, y_test), 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 400/400 [00:13<00:00, 28.79batch/s, loss=2.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 3.0325488102436067; Train Accuracy = 0.0\n",
      "छॅशःूफऽओलऔईञईिईईई देशभरामध्ये\n",
      "भँधधञॅबबऽऋईऋऽखखईख पेशनधारियों\n",
      "षँईऑऑंनवञळओमओशँँख अनुक्रमानुपात\n",
      "षऔञऔऋञ़ञञगःःः@ेँई वाहिन्यांसाठी\n",
      "दषईचटॉअबऽूूुञुषषख लोकरचनाओं\n",
      "भईवःःऋछधऔटऋटववबईझ ट्रांसक्रिप्टेज़\n",
      "भॉूदटऽऽटटजऋऋचअईईख गंतिविधियों\n",
      "भःःःःःओझनयःयईईईईँ शासनाबद्दल\n",
      "भःनईधनछय़नदईढढईखख सर्वसंग्रह\n",
      "गमददषअईऋइसओफईईईईई तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 400/400 [00:13<00:00, 28.80batch/s, loss=2.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 2.7656224447488786; Train Accuracy = 0.0\n",
      "स्र््राा्या देशभरामध्ये\n",
      "स्र््रा्यां पेशनधारियों\n",
      "स््र्र्ार्र अनुक्रमानुपात\n",
      "स्रायारां वाहिन्यांसाठी\n",
      "स्र््रारं लोकरचनाओं\n",
      "स्र्र्र्रायाय ट्रांसक्रिप्टेज़\n",
      "स्ग्यार्यां गंतिविधियों\n",
      "स्र््रा्य शासनाबद्दल\n",
      "स््रार्ाय सर्वसंग्रह\n",
      "स्र््यार्ं तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 400/400 [00:13<00:00, 28.67batch/s, loss=2.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 2.47019292473793; Train Accuracy = 0.0\n",
      "कार्यायांया देशभरामध्ये\n",
      "स्र्यारारां पेशनधारियों\n",
      "अं्र्यांदार्र अनुक्रमानुपात\n",
      "किरार्यांग् वाहिन्यांसाठी\n",
      "मांानाार लोकरचनाओं\n",
      "प्र्सस्रि्स्र ट्रांसक्रिप्टेज़\n",
      "अुद्रात्रां गंतिविधियों\n",
      "सार्ययारा शासनाबद्दल\n",
      "स््या्त्य सर्वसंग्रह\n",
      "सिर्ययांगं तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 400/400 [00:13<00:00, 29.10batch/s, loss=1.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 2.1450579410791395; Train Accuracy = 0.000625\n",
      "चिश्ा्ंायया देशभरामध्ये\n",
      "प्र्ा्व्या पेशनधारियों\n",
      "अन्यायााप्तरर अनुक्रमानुपात\n",
      "वायाय्यापत्र वाहिन्यांसाठी\n",
      "मिल्ााा लोकरचनाओं\n",
      "क्र्सस््टस््टस ट्रांसक्रिप्टेज़\n",
      "बित्वाय्या गंतिविधियों\n",
      "तिर्ांा्य शासनाबद्दल\n",
      "स््तस्धा सर्वसंग्रह\n",
      "शिर्ायास्ं तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 400/400 [00:13<00:00, 28.62batch/s, loss=1.5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 1.8139053601026536; Train Accuracy = 0.0055078125\n",
      "चिश्ा्याी देशभरामध्ये\n",
      "प्श्ािनीयों पेशनधारियों\n",
      "अर्र्रांप्र्र अनुक्रमानुपात\n",
      "वहहियायाश्ी वाहिन्यांसाठी\n",
      "लाकााा्यं लोकरचनाओं\n",
      "ट्रेइस्टटिट्ट ट्रांसक्रिप्टेज़\n",
      "गरत्लायायां गंतिविधियों\n",
      "शिर्भभाचया शासनाबद्दल\n",
      "सर्वस्च्या सर्वसंग्रह\n",
      "श्द्ियातोंी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 400/400 [00:14<00:00, 28.23batch/s, loss=1.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 1.5165264144539834; Train Accuracy = 0.02517578125\n",
      "दिश्ानंाीया देशभरामध्ये\n",
      "पिच्ायंायां पेशनधारियों\n",
      "अनुकुर्ाप्पुरर अनुक्रमानुपात\n",
      "वहहनन्रासचा वाहिन्यांसाठी\n",
      "लोकाायांं लोकरचनाओं\n",
      "ट्रेनस््रिप्र ट्रांसक्रिप्टेज़\n",
      "गात्ंगधायां गंतिविधियों\n",
      "शार््दा्यी शासनाबद्दल\n",
      "सररवस्द्र सर्वसंग्रह\n",
      "तुमाासापीनी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 400/400 [00:14<00:00, 28.21batch/s, loss=1.11] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 1.3017342576384545; Train Accuracy = 0.05568359375\n",
      "दिच्ा्चच्या देशभरामध्ये\n",
      "पेशााारीयों पेशनधारियों\n",
      "अनुकररापु्पार अनुक्रमानुपात\n",
      "वहििनियासत्ठी वाहिन्यांसाठी\n",
      "मोकााााओं लोकरचनाओं\n",
      "ट्रानसपप््पा ट्रांसक्रिप्टेज़\n",
      "गारिनिकायों गंतिविधियों\n",
      "शस्मुगु्यी शासनाबद्दल\n",
      "सरववसंस्र सर्वसंग्रह\n",
      "तुम्ायापीकी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 400/400 [00:14<00:00, 27.88batch/s, loss=1.07] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 1.1268962325155736; Train Accuracy = 0.08427734375\n",
      "दिश्ा्गधीये देशभरामध्ये\n",
      "पेश््ारीयों पेशनधारियों\n",
      "अनुक्नमपपपपतत अनुक्रमानुपात\n",
      "वहििन्यासस्ठी वाहिन्यांसाठी\n",
      "लोकााननंं लोकरचनाओं\n",
      "ट्रांसपपरपप्टा ट्रांसक्रिप्टेज़\n",
      "गारिरियियों गंतिविधियों\n",
      "शसममगदद्या शासनाबद्दल\n",
      "सरववसंग्रह सर्वसंग्रह\n",
      "तुम्ियाप्कीी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 400/400 [00:15<00:00, 26.42batch/s, loss=0.766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 1.0017341522872447; Train Accuracy = 0.1105859375\n",
      "देश्ार्ध्या देशभरामध्ये\n",
      "पिश््धिियोंी पेशनधारियों\n",
      "अनुकुनाुपुरतत अनुक्रमानुपात\n",
      "वहहिन्यास्ाठी वाहिन्यांसाठी\n",
      "लोकरचाननं लोकरचनाओं\n",
      "ट्रानस््रिप्पिस ट्रांसक्रिप्टेज़\n",
      "गातिविधियों गंतिविधियों\n",
      "शासाबंद् शासनाबद्दल\n",
      "सरववसंगररह सर्वसंग्रह\n",
      "तमम्ियातीी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 400/400 [00:14<00:00, 28.50batch/s, loss=0.817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.9176895959675312; Train Accuracy = 0.13095703125\n",
      "देश्रामाकयेी देशभरामध्ये\n",
      "पेश्धारियों पेशनधारियों\n",
      "अंुकररमनपपपतत अनुक्रमानुपात\n",
      "वहहिन्यांसाठी वाहिन्यांसाठी\n",
      "लोकराननओं लोकरचनाओं\n",
      "ट्रांस््रेप्टिशन ट्रांसक्रिप्टेज़\n",
      "गातिविधियों गंतिविधियों\n",
      "शससंबदद्दल शासनाबद्दल\n",
      "सरवंसंगररह सर्वसंग्रह\n",
      "तुम््यापिकीी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 400/400 [00:14<00:00, 27.75batch/s, loss=0.728]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.8493151672184467; Train Accuracy = 0.15138671875\n",
      "देश्भहभध्या देशभरामध्ये\n",
      "पेश्नारायों पेशनधारियों\n",
      "अन्कुरूुपपुततत अनुक्रमानुपात\n",
      "वहहिन्यासस्ठी वाहिन्यांसाठी\n",
      "लोकरचनाओं लोकरचनाओं\n",
      "ट्रांस््रेप्टे ट्रांसक्रिप्टेज़\n",
      "गातिविधायों गंतिविधियों\n",
      "शससमबबद्दल शासनाबद्दल\n",
      "सर्वसंगर्ह सर्वसंग्रह\n",
      "तुम्भयापककी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11:  96%|█████████▌| 382/400 [00:14<00:00, 27.25batch/s, loss=0.743]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[441], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m25\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     p, w \u001b[39m=\u001b[39m runner\u001b[39m.\u001b[39;49mtrain_one_epoch(i, \u001b[39m0.7\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m     \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(p,w))[:\u001b[39m10\u001b[39m]:\n\u001b[1;32m      4\u001b[0m         \u001b[39mprint\u001b[39m(x,y)\n",
      "Cell \u001b[0;32mIn[410], line 71\u001b[0m, in \u001b[0;36mRunner.train_one_epoch\u001b[0;34m(self, epoch_number, tf_ratio)\u001b[0m\n\u001b[1;32m     68\u001b[0m batch_X, batch_y \u001b[39m=\u001b[39m batch_X\u001b[39m.\u001b[39mto(device), batch_y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     70\u001b[0m \u001b[39m# get the logits, preds for the current batch\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m logits, preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(batch_X, batch_y, X_lens, tf_ratio\u001b[39m=\u001b[39;49mtf_ratio)\n\u001b[1;32m     72\u001b[0m \u001b[39m# ignore loss for the first time step\u001b[39;00m\n\u001b[1;32m     73\u001b[0m targets \u001b[39m=\u001b[39m batch_y[:, \u001b[39m1\u001b[39m:]; logits \u001b[39m=\u001b[39m logits[:, \u001b[39m1\u001b[39m:, :]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[409], line 25\u001b[0m, in \u001b[0;36mEncoderDecoder.forward\u001b[0;34m(self, batch_X, batch_Y, X_lens, tf_ratio)\u001b[0m\n\u001b[1;32m     22\u001b[0m dec_input \u001b[39m=\u001b[39m batch_Y[:,\u001b[39m0\u001b[39m]\n\u001b[1;32m     24\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcell_type \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mLSTM\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m---> 25\u001b[0m     init_dec_cell_state \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mstack([torch\u001b[39m.\u001b[39;49mzeros_like(final_enc_hidden_state) \u001b[39mfor\u001b[39;49;00m _ \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(num_dec_layers)], dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     26\u001b[0m     decoder_state \u001b[39m=\u001b[39m (decoder_state, init_dec_cell_state)\n\u001b[1;32m     28\u001b[0m \u001b[39mfor\u001b[39;00m tstep \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, tarlength):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(25):\n",
    "    p, w = runner.train_one_epoch(i, 0.7)\n",
    "    for x, y in list(zip(p,w))[:10]:\n",
    "        print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
