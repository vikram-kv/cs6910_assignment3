{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS6910 Assignment 3 (RNN Frameworks for transliteration) - Without attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "import wandb\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "TARGET = 'tam'\n",
    "SOURCE = 'eng'\n",
    "SOS_SYM = '@'\n",
    "EOS_SYM = '$'\n",
    "UNK_SYM = '!'\n",
    "PAD_SYM = '%'\n",
    "\n",
    "unicode_ranges = {'tam' : [0x0B80, 0x0BFF], \n",
    "                  'eng' : [0x0061, 0x007A],\n",
    "                  'hin' : [0x0900, 0x097F]}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Functions and Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load the 'cat' (= train/val/test) data of language 'lang'\n",
    "def load_data(lang, cat):\n",
    "    fcontents = open(f'aksharantar_sampled/{lang}/{lang}_{cat}.csv','r', encoding='utf-8').readlines()\n",
    "    pairs = [tuple(l.strip().split(',')) for l in fcontents]\n",
    "    x_data, y_data = list(map(list,zip(*pairs)))\n",
    "    return x_data, y_data\n",
    "\n",
    "class Language:\n",
    "    def __init__(self, name):\n",
    "        self.lname = name\n",
    "    \n",
    "    # function to create the vocabulary using the words in 'data'\n",
    "    def create_vocabulary(self, *data):\n",
    "        symbols = set()\n",
    "        for wd in data:\n",
    "            for c in wd:\n",
    "                symbols.add(c)\n",
    "        self.symbols = symbols\n",
    "\n",
    "    # function to use unicode ranges for creating the character set\n",
    "    def create_vocabulary_range(self):\n",
    "        symbols = set()\n",
    "        begin, end = unicode_ranges[self.lname]\n",
    "        for i in range(begin, end+1):\n",
    "            if (unicodedata.category(chr(i)) != 'Cn'):\n",
    "                symbols.add(chr(i))\n",
    "        self.symbols = symbols\n",
    "    \n",
    "    def generate_mappings(self):\n",
    "        self.index2sym = {0: SOS_SYM, 1 : EOS_SYM, 2 : UNK_SYM, 3 : PAD_SYM}\n",
    "        self.sym2index = {SOS_SYM : 0, EOS_SYM : 1, UNK_SYM : 2, PAD_SYM : 3}\n",
    "        self.symbols = list(self.symbols)\n",
    "        self.symbols.sort()\n",
    "\n",
    "        for i, sym in enumerate(self.symbols):\n",
    "            self.sym2index[sym] = i + 3\n",
    "            self.index2sym[i+3] = sym\n",
    "        \n",
    "        self.num_tokens = len(self.index2sym.keys())\n",
    "    \n",
    "    def convert_to_numbers(self, word):\n",
    "        enc = [self.sym2index[SOS_SYM]]\n",
    "        for ch in word:\n",
    "            if ch in self.sym2index.keys():\n",
    "                enc.append(self.sym2index[ch])\n",
    "            else:\n",
    "                enc.append(self.sym2index[UNK_SYM])\n",
    "        enc.append(self.sym2index[EOS_SYM])\n",
    "        return enc\n",
    "\n",
    "    def get_index(self, sym):\n",
    "        return self.sym2index[sym]\n",
    "    \n",
    "    def get_size(self):\n",
    "        return self.num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples = 51200\n",
      "Number of valid samples = 4096\n",
      "Number of test samples = 4096\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = load_data(TARGET, 'train')\n",
    "x_valid, y_valid = load_data(TARGET, 'valid')\n",
    "x_test, y_test = load_data(TARGET, 'test')\n",
    "\n",
    "print(f'Number of train samples = {len(x_train)}')\n",
    "print(f'Number of valid samples = {len(x_valid)}')\n",
    "print(f'Number of test samples = {len(x_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Vocabulary Size = 26\n",
      "Source Vocabulary = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Source Mapping {0: '@', 1: '$', 2: 'a', 3: 'b', 4: 'c', 5: 'd', 6: 'e', 7: 'f', 8: 'g', 9: 'h', 10: 'i', 11: 'j', 12: 'k', 13: 'l', 14: 'm', 15: 'n', 16: 'o', 17: 'p', 18: 'q', 19: 'r', 20: 's', 21: 't', 22: 'u', 23: 'v', 24: 'w', 25: 'x', 26: 'y', 27: 'z'}\n",
      "Target Vocabulary Size = 72\n",
      "Target Vocabulary = ['ஂ', 'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ', 'ஊ', 'எ', 'ஏ', 'ஐ', 'ஒ', 'ஓ', 'ஔ', 'க', 'ங', 'ச', 'ஜ', 'ஞ', 'ட', 'ண', 'த', 'ந', 'ன', 'ப', 'ம', 'ய', 'ர', 'ற', 'ல', 'ள', 'ழ', 'வ', 'ஶ', 'ஷ', 'ஸ', 'ஹ', 'ா', 'ி', 'ீ', 'ு', 'ூ', 'ெ', 'ே', 'ை', 'ொ', 'ோ', 'ௌ', '்', 'ௐ', 'ௗ', '௦', '௧', '௨', '௩', '௪', '௫', '௬', '௭', '௮', '௯', '௰', '௱', '௲', '௳', '௴', '௵', '௶', '௷', '௸', '௹', '௺']\n",
      "Target Mapping {0: '@', 1: '$', 2: 'ஂ', 3: 'ஃ', 4: 'அ', 5: 'ஆ', 6: 'இ', 7: 'ஈ', 8: 'உ', 9: 'ஊ', 10: 'எ', 11: 'ஏ', 12: 'ஐ', 13: 'ஒ', 14: 'ஓ', 15: 'ஔ', 16: 'க', 17: 'ங', 18: 'ச', 19: 'ஜ', 20: 'ஞ', 21: 'ட', 22: 'ண', 23: 'த', 24: 'ந', 25: 'ன', 26: 'ப', 27: 'ம', 28: 'ய', 29: 'ர', 30: 'ற', 31: 'ல', 32: 'ள', 33: 'ழ', 34: 'வ', 35: 'ஶ', 36: 'ஷ', 37: 'ஸ', 38: 'ஹ', 39: 'ா', 40: 'ி', 41: 'ீ', 42: 'ு', 43: 'ூ', 44: 'ெ', 45: 'ே', 46: 'ை', 47: 'ொ', 48: 'ோ', 49: 'ௌ', 50: '்', 51: 'ௐ', 52: 'ௗ', 53: '௦', 54: '௧', 55: '௨', 56: '௩', 57: '௪', 58: '௫', 59: '௬', 60: '௭', 61: '௮', 62: '௯', 63: '௰', 64: '௱', 65: '௲', 66: '௳', 67: '௴', 68: '௵', 69: '௶', 70: '௷', 71: '௸', 72: '௹', 73: '௺'}\n"
     ]
    }
   ],
   "source": [
    "# create language objects for storing vocabulary, index2sym and sym2index\n",
    "SRC_LANG = Language(SOURCE)\n",
    "TAR_LANG = Language(TARGET)\n",
    "\n",
    "# creating vocabulary using train data only\n",
    "SRC_LANG.create_vocabulary(*(x_train))\n",
    "TAR_LANG.create_vocabulary(*(y_train))\n",
    "\n",
    "# otherwise, use unicode characters (assigned codepoints) in the script's range\n",
    "# src_lang.create_vocabulary_range()\n",
    "# tar_lang.create_vocabulary_range()\n",
    "\n",
    "# generate mappings from characters to numbers and vice versa\n",
    "SRC_LANG.generate_mappings()\n",
    "TAR_LANG.generate_mappings()\n",
    "\n",
    "print(f'Source Vocabulary Size = {len(SRC_LANG.symbols)}')\n",
    "print(f'Source Vocabulary = {SRC_LANG.symbols}')\n",
    "print(f'Source Mapping {SRC_LANG.index2sym}')\n",
    "print(f'Target Vocabulary Size = {len(TAR_LANG.symbols)}')\n",
    "print(f'Target Vocabulary = {TAR_LANG.symbols}')\n",
    "print(f'Target Mapping {TAR_LANG.index2sym}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransliterateDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data, src_lang : Language, tar_lang : Language):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        self.src_lang = src_lang\n",
    "        self.tar_lang = tar_lang\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.x_data[idx], self.y_data[idx]\n",
    "        x = self.src_lang.convert_to_numbers(x)\n",
    "        y = self.tar_lang.convert_to_numbers(y) \n",
    "        return torch.Tensor(x), torch.Tensor(y)\n",
    "\n",
    "class CollationFunction:\n",
    "    def __init__(self, src_lang : Language, tar_lang : Language):\n",
    "        self.src_lang = src_lang\n",
    "        self.tar_lang = tar_lang\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        # sorting is to save encoder computation. \n",
    "        # reasoning : https://stackoverflow.com/questions/51030782/why-do-we-pack-the-sequences-in-pytorch\n",
    "        batch = batch.sort(key = lambda x : len(x[0]))\n",
    "        src, tar = zip(*batch)\n",
    "        src_lens = torch.tensor([len(x) for x in src])\n",
    "        src = nn.utils.rnn.pad_sequence(list(src), batch_first=True, padding_value=src_lang.get_index(PAD_SYM))\n",
    "        tar = nn.utils.rnn.pad_sequence(list(tar), batch_first=True, padding_value=tar_lang.get_index(PAD_SYM))\n",
    "        return src, tar, src_lens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderNet(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_layers, hid_size, cell_type, \n",
    "                 bidirect=False, dropout=0):\n",
    "        super(EncoderNet, self).__init__()\n",
    "        self.hidden_size = hid_size\n",
    "        self.embed_size = embed_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # we create the required architecture using the received parameters\n",
    "        if cell_type == 'RNN':\n",
    "            self.network = nn.RNN(input_size=embed_size, hidden_size=hid_size, num_layers=num_layers, \n",
    "                               dropout=dropout, bidirectional=bidirect, batch_first=True)\n",
    "        elif cell_type == 'LSTM':\n",
    "            self.network = nn.LSTM(input_size=embed_size, hidden_size=hid_size, num_layers=num_layers, \n",
    "                               dropout=dropout, bidirectional=bidirect, batch_first=True)\n",
    "        else:\n",
    "            self.network = nn.GRU(input_size=embed_size, hidden_size=hid_size, num_layers=num_layers, \n",
    "                               dropout=dropout, bidirectional=bidirect, batch_first=True)\n",
    "        \n",
    "        self.cell_type = cell_type\n",
    "        self.bidirect = bidirect\n",
    "\n",
    "        # for combining the final layer's forward and reverse directions' final hidden state\n",
    "        if (self.bidirect):\n",
    "            self.combine_forward_backward = nn.Linear(2 * hid_size, hid_size)\n",
    "\n",
    "        self.init_hidden_state()\n",
    "\n",
    "    def init_states(self):\n",
    "        num_dir = 2 if self.bidirect else 1\n",
    "        self.init_hidden_state = torch.zeros(num_dir * self.num_layers, self.hidden_size,requires_grad=True)\n",
    "\n",
    "        if self.cell_type == 'LSTM':\n",
    "            self.init_cell_state = torch.zeros(num_dir * self.num_layers, self.hidden_size, requires_grad=True)\n",
    "\n",
    "    def forward(self, batch_x, batch_lens):\n",
    "        batch_x = self.embedding(batch_x)\n",
    "        batch_x = self.dropout(batch_x)\n",
    "\n",
    "        ## IMPORTANT - Try sorted=False as well here\n",
    "        packed_batch_x = nn.utils.rnn.pack_padded_sequence(batch_x, lengths=batch_lens, batch_first=True, \n",
    "                                                           enforce_sorted=True)\n",
    "\n",
    "        hidden_states_stack = torch.stack([self.init_hidden_state for _ in range(self.num_layers)], dim=1)\n",
    "        if self.cell_type == 'LSTM':\n",
    "            cell_states_stack = torch.stack([self.init_cell_state for _ in range(self.num_layers)], dim=1)\n",
    "            packed_outputs, (hidden_outputs, cell_outputs) = self.network(packed_batch_x, hidden_states_stack, cell_states_stack)\n",
    "        else:\n",
    "            packed_outputs, hidden_outputs = self.network(packed_batch_x, hidden_states_stack)\n",
    "        \n",
    "        outputs, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_outputs, batch_first=True)\n",
    "\n",
    "        if self.bidirect:\n",
    "            # remember 2nd dim in hidden_outputs; so, we have to concatenate forward and backward\n",
    "            # final hidden states along **1st dimension**\n",
    "            concat_hidden_state = torch.cat((hidden_outputs[-2,:,:], hidden_outputs[-1,:,:]), dim=1)\n",
    "            hidden_state = self.combine_forward_backward(concat_hidden_state)\n",
    "            hidden_state = torch.tanh(hidden_state)\n",
    "        # hidden_state = (batch_size, hid_size); outputs = (batch_size, max_seq_len_batch, D * hid_size)\n",
    "        # d = 2 if bidirectional; else d = 1\n",
    "        return outputs, hidden_state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderNet(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_layers, hid_size, cell_type, \n",
    "                 dropout=0):\n",
    "        super(EncoderNet, self).__init__()\n",
    "        self.hidden_size = hid_size\n",
    "        self.embed_size = embed_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.num_layers = num_layers\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        # we create the required architecture using the received parameters\n",
    "        if cell_type == 'RNN':\n",
    "            self.network = nn.RNN(input_size=embed_size, hidden_size=hid_size, num_layers=num_layers, \n",
    "                               dropout=dropout, batch_first=True)\n",
    "        elif cell_type == 'LSTM':\n",
    "            self.network = nn.LSTM(input_size=embed_size, hidden_size=hid_size, num_layers=num_layers, \n",
    "                               dropout=dropout, batch_first=True)\n",
    "        else:\n",
    "            self.network = nn.GRU(input_size=embed_size, hidden_size=hid_size, num_layers=num_layers, \n",
    "                               dropout=dropout, batch_first=True)\n",
    "        \n",
    "        self.cell_type = cell_type\n",
    "        self.out_layer = nn.Linear(hid_size, vocab_size)\n",
    "\n",
    "    # will always go 1 step forward in time (seqlen = L = 1)\n",
    "    # previous decoder state shape = [num_layers, batch_size, hid_size]\n",
    "    def forward(self, batch_y, prev_decoder_state):\n",
    "        batch_y = batch_y.unsqueeze(1) # batch_size is first dim\n",
    "        batch_y = self.embedding(batch_y)\n",
    "        batch_y = self.dropout(batch_y)\n",
    "\n",
    "        if self.cell_type == 'LSTM':\n",
    "            outputs, (decoder_hidden_state, _) = self.network(batch_y, prev_decoder_state)\n",
    "        else:\n",
    "            outputs, decoder_hidden_state = self.network(batch_y, prev_decoder_state)\n",
    "        \n",
    "        outputs = outputs.squeeze(1) # remove seqlen dimension\n",
    "        logits = self.out_layer(outputs)\n",
    "        return logits, decoder_hidden_state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq(Encoder-Decoder) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore changing teacher forcing ratio to something epoch-based as sir suggested\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder :EncoderNet, decoder : DecoderNet, src_lang, tar_lang, tf_ratio) -> None:\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.enc_model = encoder\n",
    "        self.dec_model = decoder\n",
    "        self.src_lang = src_lang\n",
    "        self.tar_lang = tar_lang\n",
    "        self.tf_ratio = tf_ratio\n",
    "    \n",
    "    def forward(self, batch_X, X_lens, batch_Y):\n",
    "        batch_size = batch_X.size(0)\n",
    "        _, final_hidden_states = self.enc_model.forward(batch_X, X_lens)\n",
    "        \n",
    "        num_dec_layers = self.dec_model.num_layers\n",
    "        hidden_dec = torch.stack([final_hidden_states for _ in num_dec_layers], dim=0)\n",
    "        # we will feed the encoder output into each decoder layer's initial hidden state\n",
    "        # hidden_dec = (num_layers, batch_size, hid_size)\n",
    "\n",
    "        tarlength = batch_Y.size(1)\n",
    "        outlogits = torch.zeros(batch_size, tarlength, self.dec_model.vocab_size).to(device)\n",
    "        dec_input = batch_Y[:,0]\n",
    "\n",
    "        for tstep in range(1, tarlength):\n",
    "            curlogits, hidden_dec = self.dec_model.forward(dec_input, hidden_dec)\n",
    "            dec_input = batch_Y[:, tstep]\n",
    "            pred = torch.argmax(curlogits, dim=1)\n",
    "            rand_numbers = torch.randn(batch_size)\n",
    "            dec_input = torch.where(rand_numbers > self.tf_ratio, dec_input, pred)\n",
    "            outlogits[:, tstep, :] = curlogits \n",
    "\n",
    "        return outlogits  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Evaluation/Inference Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner():\n",
    "    def __init__(self, src_lang : Language, tar_lang : Language, common_embed_size, num_enc_layers, num_dec_layers, \n",
    "                 common_hidden_size, common_cell_type, enc_bidirect, dropout, tf_ratio):\n",
    "        \n",
    "        encoder = EncoderNet(vocab_size=src_lang.get_size(), embed_size=common_embed_size,\n",
    "                             num_layers=num_enc_layers, hid_size=common_hidden_size,\n",
    "                             cell_type= common_cell_type, bidirect=enc_bidirect, dropout=dropout)\n",
    "        decoder = DecoderNet(vocab_size=tar_lang.get_size(), embed_size=common_embed_size,\n",
    "                             num_layers=num_dec_layers, hid_size=common_hidden_size,\n",
    "                             cell_type=common_cell_type, dropout=dropout)\n",
    "        model = EncoderDecoder(encoder=encoder, decoder=decoder, src_lang=src_lang, tar_lang=tar_lang,\n",
    "                               tf_ratio=0.6)\n",
    "        model.to(device)\n",
    "        # for reproducibility - seed everything with 42\n",
    "        torch.manual_seed(42); torch.cuda.manual_seed(42); np.random.seed(42); random.seed(42)\n",
    "        model.apply(self.init_weights) # initialize model weights\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(model : nn.Module, a=-0.08, b=0.08):\n",
    "        for _, param in model.named_parameters():\n",
    "            nn.init.uniform_(param.data, -0.0)\n",
    "    \n",
    "    def generate_data_loaders(self, train=True, data_X, data_y, batch_size):\n",
    "        dataset = TransliterateDataset(data_X, data_y, src_lang=SRC_LANG, tar_lang=TAR_LANG)\n",
    "        dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                                shuffle=True, collate_fn=CollationFunction(SRC_LANG, TAR_LANG))\n",
    "        return dataloader\n",
    "\n",
    "    def train(self, ):\n",
    "        pass\n",
    "    def evaluate(self, ):\n",
    "        pass\n",
    "    def inference(self, ):\n",
    "        pass\n",
    "\n",
    "    def beam_search_inference(self, ):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
