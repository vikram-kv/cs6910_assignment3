{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Model with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries for the notebook\n",
    "import lightning as lt\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import torch\n",
    "from language import *\n",
    "from dataset_dataloader import *\n",
    "from encoder_decoder import *\n",
    "from plotting_code_and_helpers import *\n",
    "from runner import Runner\n",
    "import argparse as ap\n",
    "import os, shutil\n",
    "\n",
    "# we will ignore num_workers suggestions/warnings from pytorch-lightning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# know the accelerator available - NOT USED as we have switched to lightning\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the source and target languages and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the source and target languages\n",
    "TARGET = 'tam'\n",
    "SOURCE = 'eng'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples = 51200\n",
      "Number of valid samples = 4096\n",
      "Number of test samples = 4096\n"
     ]
    }
   ],
   "source": [
    "# load all the available data and print sample counts for each set\n",
    "x_train, y_train = load_data(TARGET, 'train')\n",
    "x_valid, y_valid = load_data(TARGET, 'valid')\n",
    "x_test, y_test = load_data(TARGET, 'test')\n",
    "\n",
    "print(f'Number of train samples = {len(x_train)}')\n",
    "print(f'Number of valid samples = {len(x_valid)}')\n",
    "print(f'Number of test samples = {len(x_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Vocabulary Size = 26\n",
      "Source Vocabulary = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Source Mapping {0: '@', 1: '$', 2: '!', 3: '%', 4: 'a', 5: 'b', 6: 'c', 7: 'd', 8: 'e', 9: 'f', 10: 'g', 11: 'h', 12: 'i', 13: 'j', 14: 'k', 15: 'l', 16: 'm', 17: 'n', 18: 'o', 19: 'p', 20: 'q', 21: 'r', 22: 's', 23: 't', 24: 'u', 25: 'v', 26: 'w', 27: 'x', 28: 'y', 29: 'z'}\n",
      "Target Vocabulary Size = 46\n",
      "Target Vocabulary = ['ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ', 'ஊ', 'எ', 'ஏ', 'ஐ', 'ஒ', 'ஓ', 'க', 'ங', 'ச', 'ஜ', 'ஞ', 'ட', 'ண', 'த', 'ந', 'ன', 'ப', 'ம', 'ய', 'ர', 'ற', 'ல', 'ள', 'ழ', 'வ', 'ஷ', 'ஸ', 'ஹ', 'ா', 'ி', 'ீ', 'ு', 'ூ', 'ெ', 'ே', 'ை', 'ொ', 'ோ', 'ௌ', '்']\n",
      "Target Mapping {0: '@', 1: '$', 2: '!', 3: '%', 4: 'ஃ', 5: 'அ', 6: 'ஆ', 7: 'இ', 8: 'ஈ', 9: 'உ', 10: 'ஊ', 11: 'எ', 12: 'ஏ', 13: 'ஐ', 14: 'ஒ', 15: 'ஓ', 16: 'க', 17: 'ங', 18: 'ச', 19: 'ஜ', 20: 'ஞ', 21: 'ட', 22: 'ண', 23: 'த', 24: 'ந', 25: 'ன', 26: 'ப', 27: 'ம', 28: 'ய', 29: 'ர', 30: 'ற', 31: 'ல', 32: 'ள', 33: 'ழ', 34: 'வ', 35: 'ஷ', 36: 'ஸ', 37: 'ஹ', 38: 'ா', 39: 'ி', 40: 'ீ', 41: 'ு', 42: 'ூ', 43: 'ெ', 44: 'ே', 45: 'ை', 46: 'ொ', 47: 'ோ', 48: 'ௌ', 49: '்'}\n"
     ]
    }
   ],
   "source": [
    "# create language objects for storing vocabulary, index2sym and sym2index\n",
    "SRC_LANG = Language(SOURCE)\n",
    "TAR_LANG = Language(TARGET)\n",
    "\n",
    "# creating vocabulary using train data only\n",
    "SRC_LANG.create_vocabulary(*(x_train))\n",
    "TAR_LANG.create_vocabulary(*(y_train))\n",
    "\n",
    "# generate mappings from characters to numbers and vice versa\n",
    "SRC_LANG.generate_mappings()\n",
    "TAR_LANG.generate_mappings()\n",
    "\n",
    "# print the source and target vocabularies\n",
    "print(f'Source Vocabulary Size = {len(SRC_LANG.symbols)}')\n",
    "print(f'Source Vocabulary = {SRC_LANG.symbols}')\n",
    "print(f'Source Mapping {SRC_LANG.index2sym}')\n",
    "print(f'Target Vocabulary Size = {len(TAR_LANG.symbols)}')\n",
    "print(f'Target Vocabulary = {TAR_LANG.symbols}')\n",
    "print(f'Target Mapping {TAR_LANG.index2sym}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the model (from checkpoint artifacts fetched from wandb) and run inference on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03755331039428711,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57626267c277439f929cfbb3f3297fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      0.635009765625       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7446691989898682     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.635009765625      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7446691989898682    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012076854705810547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Testing",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d80bc30177492d8ec254f103189df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">         0.5234375         </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.1686042547225952     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m        0.5234375        \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.1686042547225952    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dictionary to pass to a model (instance of Runner Class)\n",
    "# we use the best hypermeters from the sweep\n",
    "rdict = dict(\n",
    "            SOURCE=SOURCE,\n",
    "            TARGET=TARGET,\n",
    "            src_lang=SRC_LANG,\n",
    "            tar_lang=TAR_LANG,\n",
    "            common_embed_size=192,\n",
    "            common_num_layers=1,\n",
    "            common_hidden_size=256,\n",
    "            common_cell_type='LSTM',\n",
    "            init_tf_ratio= 0.7,\n",
    "            enc_bidirect=True,\n",
    "            attention=True,\n",
    "            dropout=0.0,\n",
    "            opt_name='Adam',\n",
    "            learning_rate=0.002,\n",
    "            batch_size=128\n",
    ")\n",
    "\n",
    "#### TESTING SECTION ####\n",
    "trainer = lt.Trainer()\n",
    "# load the best model (saved locally in './best_checkpoints/attention/')\n",
    "run_name = 'emb=192_layers=1_hid=256_cell=LSTM_bidirectional=True_dr=0_itfr=0.7_bsize=128_att=True_opt=Adam_lr=0.002'\n",
    "runner = Runner.load_from_checkpoint(f'./best_checkpoints/attention/{run_name}.ckpt', **rdict)\n",
    "\n",
    "trainer.validate(runner) # display validation accuracy to verify with wandb - 63.50 expected\n",
    "trainer.test(runner)\n",
    "\n",
    "# get the test results and unpack it\n",
    "ret_info = runner.get_test_results()\n",
    "src_list, tar_true_list, tar_pred_list, attn_matrices = ret_info\n",
    "\n",
    "# save the predictions in predictions.csv within predictions_attention folder\n",
    "if os.path.exists('./predictions_attention/'):\n",
    "    shutil.rmtree('./predictions_attention/')\n",
    "os.mkdir('./predictions_attention/')\n",
    "save_predictions_file(src_list, tar_true_list, tar_pred_list, './predictions_attention/predictions')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log a color-coded table and attention heatmaps for wandb report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs19b021\u001b[0m (\u001b[33mcs6700_team_2023\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/vikram/Desktop/Deep Learning/cs6910_assignment3/wandb/run-20230518_234728-93itaxjk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs19b021/cs6910-assignment3/runs/93itaxjk' target=\"_blank\">att_compare</a></strong> to <a href='https://wandb.ai/cs19b021/cs6910-assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs19b021/cs6910-assignment3' target=\"_blank\">https://wandb.ai/cs19b021/cs6910-assignment3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs19b021/cs6910-assignment3/runs/93itaxjk' target=\"_blank\">https://wandb.ai/cs19b021/cs6910-assignment3/runs/93itaxjk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db2c3c7219ef4391b01cf780e7f714b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.008 MB of 0.026 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.319800…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">att_compare</strong> at: <a href='https://wandb.ai/cs19b021/cs6910-assignment3/runs/93itaxjk' target=\"_blank\">https://wandb.ai/cs19b021/cs6910-assignment3/runs/93itaxjk</a><br/>Synced 4 W&B file(s), 2 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230518_234728-93itaxjk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with wandb.init(project='cs6910-assignment3', entity='cs19b021', tags=['att-words-log'], name='att_compare') as run:\n",
    "    word_numbers = [103, 188, 366, 401, 1176, 2281, 2691, 2985, 3374, 3787]\n",
    "    df = pd.read_csv(f'./predictions_attention/predictions.csv')\n",
    "    df = df[[\"Source\", \"Target\", \"Predicted\"]]\n",
    "    df.insert(0, \"Word number\", [i for i in range(1, len(df)+1)]) \n",
    "    f1, f2 = generate_table_and_legend(df, locs=[(r-1) for r in word_numbers])\n",
    "    wandb.log({\"word-table\" : f1})\n",
    "    wandb.log({\"legend\" : f2})\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba39c64bd5f74790a5142eb4b4f625a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669640916613087, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/vikram/Desktop/Deep Learning/cs6910_assignment3/wandb/run-20230518_233219-uiwa4g6q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs19b021/cs6910-assignment3/runs/uiwa4g6q' target=\"_blank\">best_attention_model_heatmaps</a></strong> to <a href='https://wandb.ai/cs19b021/cs6910-assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs19b021/cs6910-assignment3' target=\"_blank\">https://wandb.ai/cs19b021/cs6910-assignment3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs19b021/cs6910-assignment3/runs/uiwa4g6q' target=\"_blank\">https://wandb.ai/cs19b021/cs6910-assignment3/runs/uiwa4g6q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb31e2bd817f4cf3aa03a2cb9ccd276a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.029 MB of 0.036 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.797941…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">best_attention_model_heatmaps</strong> at: <a href='https://wandb.ai/cs19b021/cs6910-assignment3/runs/uiwa4g6q' target=\"_blank\">https://wandb.ai/cs19b021/cs6910-assignment3/runs/uiwa4g6q</a><br/>Synced 4 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230518_233219-uiwa4g6q/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with wandb.init(project='cs6910-assignment3', entity='cs19b021', tags=['att-heatmap'], name='best_attention_model_heatmaps') as run:\n",
    "    word_numbers = [3602, 947, 2808, 1414, 279, 393, 57, 109, 3144, 1612]\n",
    "    fig = generate_heatmap_grid(src_list, tar_true_list, tar_pred_list, attn_matrices, word_numbers)\n",
    "    wandb.log({\"attention-plot\" : fig})\n",
    "    run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
