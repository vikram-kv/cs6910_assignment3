{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries for the notebook\n",
    "import lightning as lt\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger, TensorBoardLogger\n",
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "import torch.nn as nn\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from torchaudio.functional import edit_distance as edit_dist\n",
    "import random\n",
    "from language import *\n",
    "from dataset_dataloader import *\n",
    "from encoder_decoder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# know the accelerator available - NOT USED as we have switched to lightning\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the source and target languages and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the source and target languages\n",
    "TARGET = 'tam'\n",
    "SOURCE = 'eng'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples = 51200\n",
      "Number of valid samples = 4096\n",
      "Number of test samples = 4096\n"
     ]
    }
   ],
   "source": [
    "# load all the available data and print sample counts for each set\n",
    "x_train, y_train = load_data(TARGET, 'train')\n",
    "x_valid, y_valid = load_data(TARGET, 'valid')\n",
    "x_test, y_test = load_data(TARGET, 'test')\n",
    "\n",
    "print(f'Number of train samples = {len(x_train)}')\n",
    "print(f'Number of valid samples = {len(x_valid)}')\n",
    "print(f'Number of test samples = {len(x_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Vocabulary Size = 26\n",
      "Source Vocabulary = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Source Mapping {0: '@', 1: '$', 2: '!', 3: '%', 4: 'a', 5: 'b', 6: 'c', 7: 'd', 8: 'e', 9: 'f', 10: 'g', 11: 'h', 12: 'i', 13: 'j', 14: 'k', 15: 'l', 16: 'm', 17: 'n', 18: 'o', 19: 'p', 20: 'q', 21: 'r', 22: 's', 23: 't', 24: 'u', 25: 'v', 26: 'w', 27: 'x', 28: 'y', 29: 'z'}\n",
      "Target Vocabulary Size = 46\n",
      "Target Vocabulary = ['ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ', 'ஊ', 'எ', 'ஏ', 'ஐ', 'ஒ', 'ஓ', 'க', 'ங', 'ச', 'ஜ', 'ஞ', 'ட', 'ண', 'த', 'ந', 'ன', 'ப', 'ம', 'ய', 'ர', 'ற', 'ல', 'ள', 'ழ', 'வ', 'ஷ', 'ஸ', 'ஹ', 'ா', 'ி', 'ீ', 'ு', 'ூ', 'ெ', 'ே', 'ை', 'ொ', 'ோ', 'ௌ', '்']\n",
      "Target Mapping {0: '@', 1: '$', 2: '!', 3: '%', 4: 'ஃ', 5: 'அ', 6: 'ஆ', 7: 'இ', 8: 'ஈ', 9: 'உ', 10: 'ஊ', 11: 'எ', 12: 'ஏ', 13: 'ஐ', 14: 'ஒ', 15: 'ஓ', 16: 'க', 17: 'ங', 18: 'ச', 19: 'ஜ', 20: 'ஞ', 21: 'ட', 22: 'ண', 23: 'த', 24: 'ந', 25: 'ன', 26: 'ப', 27: 'ம', 28: 'ய', 29: 'ர', 30: 'ற', 31: 'ல', 32: 'ள', 33: 'ழ', 34: 'வ', 35: 'ஷ', 36: 'ஸ', 37: 'ஹ', 38: 'ா', 39: 'ி', 40: 'ீ', 41: 'ு', 42: 'ூ', 43: 'ெ', 44: 'ே', 45: 'ை', 46: 'ொ', 47: 'ோ', 48: 'ௌ', 49: '்'}\n"
     ]
    }
   ],
   "source": [
    "# create language objects for storing vocabulary, index2sym and sym2index\n",
    "SRC_LANG = Language(SOURCE)\n",
    "TAR_LANG = Language(TARGET)\n",
    "\n",
    "# creating vocabulary using train data only\n",
    "SRC_LANG.create_vocabulary(*(x_train))\n",
    "TAR_LANG.create_vocabulary(*(y_train))\n",
    "\n",
    "# generate mappings from characters to numbers and vice versa\n",
    "SRC_LANG.generate_mappings()\n",
    "TAR_LANG.generate_mappings()\n",
    "\n",
    "# print the source and target vocabularies\n",
    "print(f'Source Vocabulary Size = {len(SRC_LANG.symbols)}')\n",
    "print(f'Source Vocabulary = {SRC_LANG.symbols}')\n",
    "print(f'Source Mapping {SRC_LANG.index2sym}')\n",
    "print(f'Target Vocabulary Size = {len(TAR_LANG.symbols)}')\n",
    "print(f'Target Vocabulary = {TAR_LANG.symbols}')\n",
    "print(f'Target Mapping {TAR_LANG.index2sym}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runner Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner(lt.LightningModule):\n",
    "    def __init__(self, src_lang : Language, tar_lang : Language, common_embed_size, common_num_layers, \n",
    "                 common_hidden_size, common_cell_type, init_tf_ratio = 0.8, enc_bidirect=False, attention=False, dropout=0.0, \n",
    "                 opt_name='Adam', learning_rate=2e-3, batch_size=32):\n",
    "    \n",
    "        super(Runner,self).__init__()\n",
    "        # save the language objects\n",
    "        self.src_lang = src_lang\n",
    "        self.tar_lang = tar_lang\n",
    "\n",
    "        # create all the sub-networks and the main model\n",
    "        self.encoder = EncoderNet(vocab_size=src_lang.get_size(), embed_size=common_embed_size,\n",
    "                             num_layers=common_num_layers, hid_size=common_hidden_size,\n",
    "                             cell_type=common_cell_type, bidirect=enc_bidirect, dropout=dropout)\n",
    "        if attention:\n",
    "            self.attention = True\n",
    "            self.attn_layer = Attention(common_hidden_size, enc_bidirect)\n",
    "        else:\n",
    "            self.attention = False\n",
    "            self.attn_layer = None\n",
    "        \n",
    "        self.decoder = DecoderNet(vocab_size=tar_lang.get_size(), embed_size=common_embed_size,\n",
    "                             num_layers=common_num_layers, hid_size=common_hidden_size,\n",
    "                             cell_type=common_cell_type, attention=attention, attn_layer=self.attn_layer,\n",
    "                             enc_bidirect=enc_bidirect, dropout=dropout)\n",
    "        \n",
    "        self.model = EncoderDecoder(encoder=self.encoder, decoder=self.decoder, src_lang=src_lang, \n",
    "                                    tar_lang=tar_lang)\n",
    "\n",
    "        # for determinism\n",
    "        torch.manual_seed(42); torch.cuda.manual_seed(42); np.random.seed(42); random.seed(42)\n",
    "\n",
    "        self.model.apply(self.init_weights) # initialize model weights\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # optimizer for the model and loss function [that ignores locs where target = PAD token]\n",
    "        self.loss_criterion = nn.CrossEntropyLoss(ignore_index=tar_lang.sym2index[PAD_SYM])\n",
    "        self.opt_name = opt_name\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # only adam is present in configure_optimizers as of now\n",
    "        if (opt_name != 'Adam'):\n",
    "            exit(-1)\n",
    "        \n",
    "        self.pred_train_words = []; self.true_train_words = []\n",
    "        self.pred_valid_words = []; self.true_valid_words = []\n",
    "        self.test_X_words = []; self.pred_test_words = []; self.true_test_words = []\n",
    "        self.save_test_preds = False\n",
    "        self.cur_tf_ratio = init_tf_ratio\n",
    "        self.min_tf_ratio = 0.01\n",
    "        self.attn_matrices = []  # used only when there is attention layer\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = None\n",
    "        if self.opt_name == 'Adam':\n",
    "            optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        '''\n",
    "        function to initialize the weights of the model parameters\n",
    "        '''\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                 nn.init.uniform_(param.data, -0.04, 0.04)\n",
    "            else:\n",
    "                nn.init.constant_(param.data, 0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def exact_accuracy(pred_words, tar_words):\n",
    "        ''' \n",
    "        compute the accuracy using (predicted words, target words) and return it.\n",
    "        exact word matching is used.\n",
    "        '''\n",
    "        assert(len(pred_words) == len(tar_words))\n",
    "        count = 0\n",
    "        for i in range(len(pred_words)):\n",
    "            if pred_words[i] == tar_words[i]:\n",
    "                count += 1\n",
    "        return count / len(pred_words)\n",
    "    \n",
    "    ####################\n",
    "    # DATA RELATED HOOKS\n",
    "    ####################\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # load all the available data on all GPUs\n",
    "        self.x_train, self.y_train = load_data(TARGET, 'train')\n",
    "        self.x_valid, self.y_valid = load_data(TARGET, 'valid')\n",
    "        self.x_test, self.y_test = load_data(TARGET, 'test')\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = TransliterateDataset(self.x_train, self.y_train, src_lang=SRC_LANG, tar_lang=TAR_LANG)\n",
    "        dataloader = DataLoader(dataset=dataset, batch_size=self.batch_size, collate_fn=CollationFunction(SRC_LANG, TAR_LANG))\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = TransliterateDataset(self.x_valid, self.y_valid, src_lang=SRC_LANG, tar_lang=TAR_LANG)\n",
    "        dataloader = DataLoader(dataset=dataset, batch_size=self.batch_size, collate_fn=CollationFunction(SRC_LANG, TAR_LANG))\n",
    "        return dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        dataset = TransliterateDataset(self.x_test, self.y_test, src_lang=SRC_LANG, tar_lang=TAR_LANG)\n",
    "        dataloader = DataLoader(dataset=dataset, batch_size=1, collate_fn=CollationFunction(SRC_LANG, TAR_LANG))\n",
    "        # we do inference word by word. So, batch_size = 1\n",
    "        return dataloader\n",
    "\n",
    "    ####################\n",
    "    # INTERFACE RELATED FUNCTIONS - NOTE -> heatmap; beam decoding (and save top 3 preds);\n",
    "    #                                       \n",
    "    #                                       wandb sweeping stuff and model checkpointing;\n",
    "    #                                       put all together\n",
    "    ####################\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        batch_X, batch_y, X_lens = train_batch\n",
    "        # get the logits, preds for the current batch\n",
    "        logits, preds = self.model(batch_X, batch_y, X_lens, tf_ratio=self.cur_tf_ratio)\n",
    "        # ignore loss for the first time step\n",
    "        targets = batch_y[:, 1:]; logits = logits[:, 1:, :]\n",
    "        logits = logits.swapaxes(1, 2) # make class logits the second dimension as needed\n",
    "        loss = self.loss_criterion(logits, targets)\n",
    "        # for epoch-level metrics[accuracy], log all the required data\n",
    "        self.true_train_words += self.tar_lang.convert_to_words(batch_y)\n",
    "        self.pred_train_words += self.tar_lang.convert_to_words(preds)\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        self.log('train_accuracy', self.exact_accuracy(self.pred_train_words, self.true_train_words), \n",
    "                 on_epoch=True, prog_bar=True)\n",
    "        self.pred_train_words.clear(); self.true_train_words.clear()\n",
    "\n",
    "        self.log('tf_ratio', self.cur_tf_ratio, on_epoch=True, prog_bar=True)\n",
    "        # for first 12 epochs, we dont change the tf ratio. Then we decrease it by 0.1 every epoch till\n",
    "        # min_tf_ratio is reached. This is also logged.\n",
    "        if (self.current_epoch >= 11):\n",
    "            self.cur_tf_ratio -= 0.1\n",
    "            self.cur_tf_ratio = max(self.cur_tf_ratio, self.min_tf_ratio)\n",
    "\n",
    "    def validation_step(self, valid_batch, batch_idx):\n",
    "        batch_X, batch_y, X_lens = valid_batch\n",
    "        # get the logits, preds for the current batch\n",
    "        logits, preds = self.model(batch_X, batch_y, X_lens) # no teacher forcing\n",
    "        # ignore loss for the first time step\n",
    "        targets = batch_y[:, 1:]; logits = logits[:, 1:, :]\n",
    "        logits = logits.swapaxes(1, 2) # make class logits the second dimension as needed\n",
    "        loss = self.loss_criterion(logits, targets)\n",
    "        # for epoch-level metrics[accuracy], log all the required data\n",
    "        self.true_valid_words += self.tar_lang.convert_to_words(batch_y)\n",
    "        self.pred_valid_words += self.tar_lang.convert_to_words(preds)\n",
    "        self.log('validation_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log('validation_accuracy', self.exact_accuracy(self.true_valid_words, self.pred_valid_words), \n",
    "                 on_epoch=True, prog_bar=True)\n",
    "        self.true_valid_words.clear(); self.pred_valid_words.clear()\n",
    "    \n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        batch_X, batch_y, X_lens = test_batch\n",
    "        logits, pred_word, attn_matrix = self.model.greedy_inference(batch_X, X_lens)\n",
    "        # update all the global lists\n",
    "        self.pred_test_words += pred_word\n",
    "        self.true_test_words += self.tar_lang.convert_to_words(batch_y)\n",
    "        self.test_X_words += self.src_lang.convert_to_words(batch_X)\n",
    "        # if there is attention, update the attention list also\n",
    "        if (self.attention):\n",
    "            self.attn_matrices += [attn_matrix]\n",
    "        # ignore loss for the first time step\n",
    "        targets = batch_y[:, 1:]; logits = logits[1:, :]\n",
    "        # we shrink the logits to the true decoded sequence length for loss computation alone\n",
    "        true_dec_len = targets.size(1)\n",
    "        logits = (logits[:true_dec_len, :]).swapaxes(0,1).unsqueeze(0)\n",
    "        # squeeze and swapping of dimensions is to meet condition needed by nn.CrossEntopyLoss()\n",
    "        loss = self.loss_criterion(logits, targets)\n",
    "        self.log('test_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "    \n",
    "    # will prevent clearing of global test lists on test epoch end\n",
    "    def track_test_predictions(self):\n",
    "        self.save_test_preds = True\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        self.log('test_accuracy', self.exact_accuracy(self.pred_test_words, self.true_test_words), \n",
    "                 on_epoch=True, prog_bar=True)\n",
    "        if not self.save_test_preds:\n",
    "            self.pred_test_words.clear(); self.true_test_words.clear(); self.test_X_words.clear()\n",
    "            self.attn_matrices.clear()\n",
    "    \n",
    "    # here, we will save all the predictions made and also, return a copy of the list of attention\n",
    "    # matrices for generating heatmaps\n",
    "    def save_test_predictions(self, fname='pred'):\n",
    "        edit_distances = [edit_dist(pred,tar) for pred, tar in zip(self.pred_test_words,self.true_test_words)]\n",
    "        pred_df = pd.DataFrame(zip(self.test_X_words, self.true_test_words, self.pred_test_words, edit_distances),\n",
    "                               columns=['Input', 'Target', 'Predicted', 'Levenshtein Distance'])\n",
    "        pred_df.to_csv('./'+fname+'.csv', index=False, encoding='utf-8')\n",
    "\n",
    "        # if attention layer is present, we return attention matrices as well.\n",
    "        ret_info = None\n",
    "        if self.attention:\n",
    "            ret_info = (self.test_X_words.copy(), self.pred_test_words.copy(), self.attn_matrices.copy())\n",
    "        self.save_test_preds = False\n",
    "        # clear after saving to save memory \n",
    "        self.pred_test_words.clear(); self.true_test_words.clear(); self.test_X_words.clear()\n",
    "        self.attn_matrices.clear()\n",
    "        return ret_info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model (With Attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_attention_heatmap(number, X_word, pred_word, attn_matrix :torch.Tensor):\n",
    "    x_labels = list(pred_word) + ['<E>']\n",
    "    y_labels = ['<S>'] + list(X_word) + ['<E>']\n",
    "    # we ignore the 0th timestep as it was not generated by attn_layer\n",
    "    attn_matrix = np.transpose(attn_matrix[1:,:].numpy())\n",
    "    assert(len(x_labels) == attn_matrix.shape[1])\n",
    "    assert(len(y_labels) == attn_matrix.shape[0])\n",
    "    fig = px.imshow(attn_matrix, labels=dict(x=\"Predicted character\", y=\"Source Character\", color=\"Value\"),\n",
    "                    x=x_labels, y=y_labels, title=f'Src : {X_word}\\n Pred : {pred_word}',\n",
    "                    color_continuous_scale='greys')\n",
    "    fig.update_xaxes(side=\"top\")\n",
    "    fig.show()\n",
    "    # log both the confusion matrix from wandb.plot and plotly plot along with loss, acc\n",
    "    # wandb.log({f\"Attention Plot {number}\" :  fig})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 9\n",
      "tensor([[0.2008, 0.5093, 0.5218, 0.7471, 0.0690, 0.5574, 0.4257, 0.5440, 0.3209,\n",
      "         0.3812, 0.8899],\n",
      "        [0.6010, 0.7760, 0.6995, 0.2897, 0.6082, 0.0929, 0.4723, 0.7046, 0.0971,\n",
      "         0.2403, 0.9353],\n",
      "        [0.8981, 0.8716, 0.1455, 0.6104, 0.9677, 0.3442, 0.5847, 0.7872, 0.8383,\n",
      "         0.6261, 0.5380],\n",
      "        [0.4637, 0.7016, 0.0632, 0.2449, 0.3537, 0.9507, 0.5546, 0.1838, 0.4665,\n",
      "         0.5429, 0.5275],\n",
      "        [0.3641, 0.6584, 0.5259, 0.3637, 0.6762, 0.8266, 0.2758, 0.9560, 0.4595,\n",
      "         0.5541, 0.3992],\n",
      "        [0.7002, 0.8730, 0.0284, 0.6064, 0.9715, 0.8978, 0.0923, 0.5008, 0.2959,\n",
      "         0.9820, 0.3799],\n",
      "        [0.7114, 0.3798, 0.2799, 0.0328, 0.6672, 0.5033, 0.5355, 0.5494, 0.6346,\n",
      "         0.5207, 0.2742],\n",
      "        [0.8518, 0.1962, 0.3825, 0.7030, 0.1951, 0.7911, 0.2271, 0.0896, 0.9790,\n",
      "         0.3448, 0.9414],\n",
      "        [0.4732, 0.7089, 0.0048, 0.8510, 0.9119, 0.1475, 0.7496, 0.2593, 0.1893,\n",
      "         0.0363, 0.3750],\n",
      "        [0.2973, 0.1556, 0.0940, 0.3809, 0.2579, 0.4713, 0.1464, 0.6638, 0.6962,\n",
      "         0.3533, 0.8871],\n",
      "        [0.8107, 0.0709, 0.0453, 0.0912, 0.6693, 0.7513, 0.8104, 0.7052, 0.2082,\n",
      "         0.7657, 0.9601]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred = 'அரோபிந்தோ'\n",
    "source =  'aurobindo'\n",
    "print(len(source), len(pred))\n",
    "attn_matrix = torch.rand(11, 11)\n",
    "print(attn_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Predicted character: %{x}<br>Source Character: %{y}<br>Value: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "x": [
          "அ",
          "ர",
          "ோ",
          "ப",
          "ி",
          "ந",
          "்",
          "த",
          "ோ",
          "<E>"
         ],
         "xaxis": "x",
         "y": [
          "<S>",
          "a",
          "u",
          "r",
          "o",
          "b",
          "i",
          "n",
          "d",
          "o",
          "<E>"
         ],
         "yaxis": "y",
         "z": [
          [
           0.6010100841522217,
           0.8980841040611267,
           0.46367645263671875,
           0.3641260862350464,
           0.7002280950546265,
           0.7114100456237793,
           0.8518198132514954,
           0.47315293550491333,
           0.29728496074676514,
           0.8107360601425171
          ],
          [
           0.7759653329849243,
           0.8715807795524597,
           0.7015896439552307,
           0.6583681106567383,
           0.8730440735816956,
           0.3797679543495178,
           0.19623786211013794,
           0.708931028842926,
           0.1556107997894287,
           0.07087540626525879
          ],
          [
           0.6994722485542297,
           0.14554858207702637,
           0.0632200837135315,
           0.5258608460426331,
           0.028391480445861816,
           0.2798531651496887,
           0.38254082202911377,
           0.004754364490509033,
           0.09400701522827148,
           0.04532516002655029
          ],
          [
           0.28969240188598633,
           0.610438883304596,
           0.24492043256759644,
           0.3637332320213318,
           0.6064367294311523,
           0.03279656171798706,
           0.7029740214347839,
           0.8510203957557678,
           0.3808537721633911,
           0.091225266456604
          ],
          [
           0.608188271522522,
           0.9677451848983765,
           0.35366004705429077,
           0.6762099266052246,
           0.9714627265930176,
           0.6671579480171204,
           0.19513797760009766,
           0.9118582606315613,
           0.25789088010787964,
           0.669283926486969
          ],
          [
           0.09287470579147339,
           0.34423017501831055,
           0.950692892074585,
           0.8265770077705383,
           0.8978316187858582,
           0.5033378005027771,
           0.7911331653594971,
           0.14746659994125366,
           0.471315860748291,
           0.7512788772583008
          ],
          [
           0.472297728061676,
           0.5847189426422119,
           0.5546457767486572,
           0.2757924795150757,
           0.09234398603439331,
           0.5354909896850586,
           0.22711634635925293,
           0.7496402859687805,
           0.14635759592056274,
           0.8103698492050171
          ],
          [
           0.7046401500701904,
           0.7871826887130737,
           0.18375366926193237,
           0.9560040831565857,
           0.5008406043052673,
           0.5494447946548462,
           0.08958595991134644,
           0.2592710256576538,
           0.6638469696044922,
           0.7051523327827454
          ],
          [
           0.097148597240448,
           0.8382538557052612,
           0.4665141701698303,
           0.4594835638999939,
           0.29593294858932495,
           0.6345723867416382,
           0.9789756536483765,
           0.18930214643478394,
           0.696236252784729,
           0.20823854207992554
          ],
          [
           0.24033403396606445,
           0.6261234283447266,
           0.5428810715675354,
           0.5541102290153503,
           0.9820303320884705,
           0.520698070526123,
           0.3448041081428528,
           0.03630036115646362,
           0.3533226251602173,
           0.7656886577606201
          ],
          [
           0.9352779984474182,
           0.5380229949951172,
           0.5274563431739807,
           0.3991783857345581,
           0.3798537254333496,
           0.27416694164276123,
           0.9414275288581848,
           0.375003457069397,
           0.8870666027069092,
           0.9601437449455261
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Value"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(255,255,255)"
          ],
          [
           0.125,
           "rgb(240,240,240)"
          ],
          [
           0.25,
           "rgb(217,217,217)"
          ],
          [
           0.375,
           "rgb(189,189,189)"
          ],
          [
           0.5,
           "rgb(150,150,150)"
          ],
          [
           0.625,
           "rgb(115,115,115)"
          ],
          [
           0.75,
           "rgb(82,82,82)"
          ],
          [
           0.875,
           "rgb(37,37,37)"
          ],
          [
           1,
           "rgb(0,0,0)"
          ]
         ]
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Src : aurobindo\n Pred : அரோபிந்தோ"
        },
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "side": "top",
         "title": {
          "text": "Predicted character"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Source Character"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_attention_heatmap(1, source, pred, attn_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
