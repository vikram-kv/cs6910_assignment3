{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS6910 Assignment 3 (RNN Frameworks for transliteration) - Without attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries for the notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import random\n",
    "from language import *\n",
    "from dataset_dataloader import *\n",
    "from encoder_decoder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# set the device to 'cuda' if available\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the source and target languages and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the source and target languages\n",
    "TARGET = 'hin'\n",
    "SOURCE = 'eng'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples = 51200\n",
      "Number of valid samples = 4096\n",
      "Number of test samples = 4096\n"
     ]
    }
   ],
   "source": [
    "# load all the available data and print sample counts for each set\n",
    "x_train, y_train = load_data(TARGET, 'train')\n",
    "x_valid, y_valid = load_data(TARGET, 'valid')\n",
    "x_test, y_test = load_data(TARGET, 'test')\n",
    "\n",
    "print(f'Number of train samples = {len(x_train)}')\n",
    "print(f'Number of valid samples = {len(x_valid)}')\n",
    "print(f'Number of test samples = {len(x_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Vocabulary Size = 26\n",
      "Source Vocabulary = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Source Mapping {0: '@', 1: '$', 2: '!', 3: '%', 4: 'a', 5: 'b', 6: 'c', 7: 'd', 8: 'e', 9: 'f', 10: 'g', 11: 'h', 12: 'i', 13: 'j', 14: 'k', 15: 'l', 16: 'm', 17: 'n', 18: 'o', 19: 'p', 20: 'q', 21: 'r', 22: 's', 23: 't', 24: 'u', 25: 'v', 26: 'w', 27: 'x', 28: 'y', 29: 'z'}\n",
      "Target Vocabulary Size = 64\n",
      "Target Vocabulary = ['ँ', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ऑ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'ळ', 'व', 'श', 'ष', 'स', 'ह', '़', 'ऽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॅ', 'े', 'ै', 'ॉ', 'ो', 'ौ', '्']\n",
      "Target Mapping {0: '@', 1: '$', 2: '!', 3: '%', 4: 'ँ', 5: 'ं', 6: 'ः', 7: 'अ', 8: 'आ', 9: 'इ', 10: 'ई', 11: 'उ', 12: 'ऊ', 13: 'ऋ', 14: 'ए', 15: 'ऐ', 16: 'ऑ', 17: 'ओ', 18: 'औ', 19: 'क', 20: 'ख', 21: 'ग', 22: 'घ', 23: 'ङ', 24: 'च', 25: 'छ', 26: 'ज', 27: 'झ', 28: 'ञ', 29: 'ट', 30: 'ठ', 31: 'ड', 32: 'ढ', 33: 'ण', 34: 'त', 35: 'थ', 36: 'द', 37: 'ध', 38: 'न', 39: 'प', 40: 'फ', 41: 'ब', 42: 'भ', 43: 'म', 44: 'य', 45: 'र', 46: 'ल', 47: 'ळ', 48: 'व', 49: 'श', 50: 'ष', 51: 'स', 52: 'ह', 53: '़', 54: 'ऽ', 55: 'ा', 56: 'ि', 57: 'ी', 58: 'ु', 59: 'ू', 60: 'ृ', 61: 'ॅ', 62: 'े', 63: 'ै', 64: 'ॉ', 65: 'ो', 66: 'ौ', 67: '्'}\n"
     ]
    }
   ],
   "source": [
    "# create language objects for storing vocabulary, index2sym and sym2index\n",
    "SRC_LANG = Language(SOURCE)\n",
    "TAR_LANG = Language(TARGET)\n",
    "\n",
    "# creating vocabulary using train data only\n",
    "SRC_LANG.create_vocabulary(*(x_train))\n",
    "TAR_LANG.create_vocabulary(*(y_train))\n",
    "\n",
    "# generate mappings from characters to numbers and vice versa\n",
    "SRC_LANG.generate_mappings()\n",
    "TAR_LANG.generate_mappings()\n",
    "\n",
    "# print the source and target vocabularies\n",
    "print(f'Source Vocabulary Size = {len(SRC_LANG.symbols)}')\n",
    "print(f'Source Vocabulary = {SRC_LANG.symbols}')\n",
    "print(f'Source Mapping {SRC_LANG.index2sym}')\n",
    "print(f'Target Vocabulary Size = {len(TAR_LANG.symbols)}')\n",
    "print(f'Target Vocabulary = {TAR_LANG.symbols}')\n",
    "print(f'Target Mapping {TAR_LANG.index2sym}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runner Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner():\n",
    "    def __init__(self, src_lang : Language, tar_lang : Language, common_embed_size, common_num_layers, \n",
    "                 common_hidden_size, common_cell_type, enc_bidirect, dropout, opt_name='Adam',\n",
    "                 learning_rate=1e-3):\n",
    "        # save the language objects\n",
    "        self.src_lang = src_lang\n",
    "        self.tar_lang = tar_lang\n",
    "\n",
    "        # create all the sub-networks and the main model\n",
    "        self.encoder = EncoderNet(vocab_size=src_lang.get_size(), embed_size=common_embed_size,\n",
    "                             num_layers=common_num_layers, hid_size=common_hidden_size,\n",
    "                             cell_type= common_cell_type, bidirect=enc_bidirect, dropout=dropout)\n",
    "        self.decoder = DecoderNet(vocab_size=tar_lang.get_size(), embed_size=common_embed_size,\n",
    "                             num_layers=common_num_layers, hid_size=common_hidden_size,\n",
    "                             cell_type=common_cell_type, dropout=dropout)\n",
    "        self.model = EncoderDecoder(encoder=self.encoder, decoder=self.decoder, src_lang=src_lang, \n",
    "                                    tar_lang=tar_lang)\n",
    "        \n",
    "        # move model to the torch device\n",
    "        self.model.to(device)\n",
    "        # for reproducibility - seed everything with 42\n",
    "        torch.manual_seed(42); torch.cuda.manual_seed(42); np.random.seed(42); random.seed(42)\n",
    "\n",
    "        self.model.apply(self.init_weights) # initialize model weights\n",
    "\n",
    "        # initialize the data loaders\n",
    "        self.trainLoader, self.validLoader, self.testLoader = None, None, None\n",
    "\n",
    "        # optimizer for the model and loss function [that ignores locs where target = PAD token]\n",
    "        self.optimizer = None\n",
    "        self.loss_criterion = nn.CrossEntropyLoss(ignore_index=tar_lang.sym2index[PAD_SYM])\n",
    "        if opt_name == 'Adam':\n",
    "            self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        '''\n",
    "        function to initialize the weights of the model parameters\n",
    "        '''\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.normal_(param.data, mean=0, std=0.05)\n",
    "            else:\n",
    "                nn.init.constant_(param.data, 0)\n",
    "    \n",
    "    def generate_data_loaders(self, data_X, data_y, batch_size):\n",
    "        '''\n",
    "        Create the pytorch Dataset and use it to make the dataloader. The dataloader\n",
    "        post-processes every batch to add padding\n",
    "        '''\n",
    "        dataset = TransliterateDataset(data_X, data_y, src_lang=SRC_LANG, tar_lang=TAR_LANG)\n",
    "        dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                                collate_fn=CollationFunction(SRC_LANG, TAR_LANG))\n",
    "        return dataloader\n",
    "\n",
    "    def make_all_loaders(self, train_data, valid_data, test_data, batch_size):\n",
    "        ''' \n",
    "        get train, valid, test data and create dataloaders of batches with size=batch_size\n",
    "        '''\n",
    "        train_X, train_y = train_data\n",
    "        valid_X, valid_y = valid_data\n",
    "        test_X, test_y = test_data\n",
    "\n",
    "        self.trainLoader = self.generate_data_loaders(train_X, train_y, batch_size)\n",
    "        self.validLoader = self.generate_data_loaders(valid_X, valid_y, batch_size)\n",
    "        self.testLoader = self.generate_data_loaders(test_X, test_y, batch_size)\n",
    "\n",
    "    def get_accuracy(self, pred_words, tar_words):\n",
    "        ''' \n",
    "        compute the accuracy using (predicted words, target words) and return it.\n",
    "        exact word matching is used.\n",
    "        '''\n",
    "        assert(len(pred_words) == len(tar_words))\n",
    "        count = 0\n",
    "        for i in range(len(pred_words)):\n",
    "            if pred_words[i] == tar_words[i]:\n",
    "                count += 1\n",
    "        return count / len(pred_words)\n",
    "\n",
    "    def train(self, epoch_number, tf_ratio=0.6):\n",
    "        '''\n",
    "        train the model for 1 epoch with teacher forcing ratio = tf_ratio.\n",
    "        epoch_number is displayed in the output\n",
    "        '''\n",
    "        # sanity checks \n",
    "        assert(self.trainLoader != None); assert(self.optimizer != None)\n",
    "\n",
    "        # set model in training mode for autograd to be activated\n",
    "        self.model.train(); self.optimizer.zero_grad()\n",
    "        # maintain training loss and lists of predicted and true words\n",
    "        train_loss = 0.0\n",
    "        pred_words, true_words = [], []\n",
    "        with tqdm(self.trainLoader, unit=' batch') as tqdmLoader:\n",
    "            for batch_X, batch_y, X_lens, y_words in tqdmLoader:\n",
    "                tqdmLoader.set_description(f'Epoch {epoch_number}')\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                # get the logits, preds for the current batch\n",
    "                logits, preds = self.model(batch_X, batch_y, X_lens, tf_ratio=tf_ratio)\n",
    "                # ignore loss for the first time step\n",
    "                targets = batch_y[:, 1:]; logits = logits[:, 1:, :]\n",
    "                logits = logits.swapaxes(1, 2) # make class logits the second dimension as needed\n",
    "                loss = self.loss_criterion(logits, targets); loss.backward(); train_loss += loss.item()\n",
    "                self.optimizer.step(); self.optimizer.zero_grad()\n",
    "                batch_pred_words = self.tar_lang.convert_to_words(preds.cpu().numpy())\n",
    "                tqdmLoader.set_postfix(loss=loss.item())\n",
    "                true_words += y_words; pred_words += batch_pred_words\n",
    "        train_loss /= len(self.trainLoader); train_acc = self.get_accuracy(pred_words, true_words)\n",
    "        print(f'Train Loss = {train_loss}; Train Accuracy = {train_acc * 100}')\n",
    "        return train_loss, train_acc, pred_words, true_words\n",
    "\n",
    "    def evaluate(self):\n",
    "        assert(self.validLoader != None)\n",
    "        self.model.eval()\n",
    "        valid_loss = 0.0\n",
    "        true_words, pred_words = [], []\n",
    "        with torch.no_grad():\n",
    "            with tqdm(self.validLoader, unit= ' batch') as tqdmLoader:\n",
    "                for batch_X, batch_y, X_lens, y_words in tqdmLoader:\n",
    "                    tqdmLoader.set_description(f'Validation')\n",
    "                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                    # get the logits, preds for the current batch\n",
    "                    logits, preds = self.model(batch_X, batch_y, X_lens)\n",
    "                    # ignore loss for the first time step\n",
    "                    targets = batch_y[:, 1:]; logits = logits[:, 1:, :]\n",
    "                    logits = logits.swapaxes(1, 2) # make class logits the second dimension as needed\n",
    "                    loss = self.loss_criterion(logits, targets)\n",
    "                    valid_loss += loss.item()\n",
    "                    batch_pred_words = self.tar_lang.convert_to_words(preds.cpu().numpy())\n",
    "                    tqdmLoader.set_postfix(loss=loss.item())\n",
    "                    true_words += y_words\n",
    "                    pred_words += batch_pred_words\n",
    "        valid_loss /= len(self.validLoader)\n",
    "        valid_acc = self.get_accuracy(pred_words, true_words)\n",
    "        print(f'Validation Loss = {valid_loss}; Validation Accuracy = {valid_acc * 100}')\n",
    "        return valid_loss, valid_acc, pred_words, true_words\n",
    "\n",
    "    def inference(self):\n",
    "        assert(self.testLoader != None)\n",
    "        self.model.eval()\n",
    "        pred_words, true_words = [], []\n",
    "        with torch.no_grad():\n",
    "            with tqdm(self.testLoader, unit=' batch') as tqdmLoader:\n",
    "                for batch_X, _, X_lens, y_words in tqdmLoader:\n",
    "                    tqdmLoader.set_description(f'Testing')\n",
    "                    batch_X = batch_X.to(device)\n",
    "                    # get the predicted words for the current batch\n",
    "                    batch_pred_words = self.model.inference_forward(batch_X, X_lens, 25)\n",
    "                    true_words += y_words\n",
    "                    pred_words += batch_pred_words\n",
    "        test_acc = self.get_accuracy(pred_words, true_words)\n",
    "        print(f'Test Accuracy = {test_acc * 100}')\n",
    "        return pred_words, true_words\n",
    "    \n",
    "    def beam_search_inference(self, ):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing runner\n",
    "# keep embedding small (around 32) -> important to get dense embedding\n",
    "# also, adjust learning rate reasonably\n",
    "runner = Runner(SRC_LANG, TAR_LANG, 32, 1, 128, 'LSTM', True, 0.1, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.make_all_loaders((x_train, y_train), (x_valid, y_valid), (x_test, y_test), 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  46%|████▋     | 186/400 [00:08<00:09, 21.87 batch/s, loss=3.05]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     _, _, p, w \u001b[39m=\u001b[39m runner\u001b[39m.\u001b[39;49mtrain(i, \u001b[39m0.6\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m     runner\u001b[39m.\u001b[39mevaluate(); runner\u001b[39m.\u001b[39minference()\n\u001b[1;32m      4\u001b[0m     \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(p,w))[:\u001b[39m10\u001b[39m]:\n",
      "Cell \u001b[0;32mIn[6], line 94\u001b[0m, in \u001b[0;36mRunner.train\u001b[0;34m(self, epoch_number, tf_ratio)\u001b[0m\n\u001b[1;32m     92\u001b[0m pred_words, true_words \u001b[39m=\u001b[39m [], []\n\u001b[1;32m     93\u001b[0m \u001b[39mwith\u001b[39;00m tqdm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainLoader, unit\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m batch\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m tqdmLoader:\n\u001b[0;32m---> 94\u001b[0m     \u001b[39mfor\u001b[39;00m batch_X, batch_y, X_lens, y_words \u001b[39min\u001b[39;00m tqdmLoader:\n\u001b[1;32m     95\u001b[0m         tqdmLoader\u001b[39m.\u001b[39mset_description(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch_number\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     96\u001b[0m         batch_X, batch_y \u001b[39m=\u001b[39m batch_X\u001b[39m.\u001b[39mto(device), batch_y\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Desktop/Deep Learning/cs6910_assignment3/dataset_dataloader.py:23\u001b[0m, in \u001b[0;36mTransliterateDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m     19\u001b[0m     \u001b[39m# gives the data point (X, y) at index = idx\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[39m# we convert them to a tensor of numbers using the Language objects\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[39m# also returns the word y for ease of computing accuracy later\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     x_enc, y_enc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_data[idx], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_data[idx]\n\u001b[0;32m---> 23\u001b[0m     x_enc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msrc_lang\u001b[39m.\u001b[39;49mconvert_to_numbers(x_enc)\n\u001b[1;32m     24\u001b[0m     y_enc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtar_lang\u001b[39m.\u001b[39mconvert_to_numbers(y_enc) \n\u001b[1;32m     25\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mtensor(x_enc, dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m), torch\u001b[39m.\u001b[39mtensor(y_enc,dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_data[idx]\n",
      "File \u001b[0;32m~/Desktop/Deep Learning/cs6910_assignment3/language.py:61\u001b[0m, in \u001b[0;36mLanguage.convert_to_numbers\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m     59\u001b[0m enc \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msym2index[SOS_SYM]]\n\u001b[1;32m     60\u001b[0m \u001b[39mfor\u001b[39;00m ch \u001b[39min\u001b[39;00m word:\n\u001b[0;32m---> 61\u001b[0m     \u001b[39mif\u001b[39;00m ch \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msym2index\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m     62\u001b[0m         enc\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msym2index[ch])\n\u001b[1;32m     63\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    _, _, p, w = runner.train(i, 0.6)\n",
    "    runner.evaluate(); runner.inference()\n",
    "    for x, y in list(zip(p,w))[:10]:\n",
    "        print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 400/400 [00:50<00:00,  7.90batch/s, loss=0.456]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.5901363408565521; Train Accuracy = 39.658203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 24.37batch/s, loss=0.918]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.1834038645029068; Validation Accuracy = 26.416015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 20.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 23.8525390625\n",
      "देशभरामध्ये देशभरामध्ये\n",
      "पेशनधारियों पेशनधारियों\n",
      "अनुक्रमानुपात अनुक्रमानुपात\n",
      "वाहिन्यांसाठीी वाहिन्यांसाठी\n",
      "लोकरचनाओं लोकरचनाओं\n",
      "ट्रांसर्प्रेस्टो ट्रांसक्रिप्टेज़\n",
      "गंतिविधियों गंतिविधियों\n",
      "शासनाबद्दल शासनाबद्दल\n",
      "सर्वसाग्र सर्वसंग्रह\n",
      "तुमच्यापाकी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 400/400 [00:51<00:00,  7.82batch/s, loss=0.388]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.5222405177354813; Train Accuracy = 44.2734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 23.63batch/s, loss=1.05] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.1828192621469498; Validation Accuracy = 26.2939453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 20.08batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 23.4619140625\n",
      "देशभरामधध्ये देशभरामध्ये\n",
      "एेशंधारियों पेशनधारियों\n",
      "अनुक्रमापुपत अनुक्रमानुपात\n",
      "वाहिन्यांसाठी वाहिन्यांसाठी\n",
      "लोकरचनाओं लोकरचनाओं\n",
      "ट्रांसर्पेेंस ट्रांसक्रिप्टेज़\n",
      "गणतिविधियों गंतिविधियों\n",
      "शासमाद्दलल शासनाबद्दल\n",
      "सर्वससंग्रह सर्वसंग्रह\n",
      "तुमच्यापैकी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 400/400 [00:50<00:00,  7.96batch/s, loss=0.381]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.4544026608020067; Train Accuracy = 48.91796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 23.58batch/s, loss=1.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.2491607461124659; Validation Accuracy = 27.685546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 20.29batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 23.6083984375\n",
      "देशभरामध्ये देशभरामध्ये\n",
      "पेशनधारियों पेशनधारियों\n",
      "अनुक्रमानुपत अनुक्रमानुपात\n",
      "वाहिन्यांसाठी वाहिन्यांसाठी\n",
      "लोकरचनाओं लोकरचनाओं\n",
      "ट्रांसर्क्रिक्ट ट्रांसक्रिप्टेज़\n",
      "गणतिविधियियों गंतिविधियों\n",
      "शशानबद्दल शासनाबद्दल\n",
      "सर्वसंग्रह सर्वसंग्रह\n",
      "तुमचचामपकी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 400/400 [00:50<00:00,  7.88batch/s, loss=0.295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.3993061497434974; Train Accuracy = 53.177734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 22.34batch/s, loss=1.1] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.269836362451315; Validation Accuracy = 25.732421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 18.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 19.2626953125\n",
      "देशभरामध्ये देशभरामध्ये\n",
      "पेशनधारियों पेशनधारियों\n",
      "अनुक्रमानुपा अनुक्रमानुपात\n",
      "वाहिन्यासाठठी वाहिन्यांसाठी\n",
      "लोकरचनाओं लोकरचनाओं\n",
      "ट्रांसक्रिप्टेज ट्रांसक्रिप्टेज़\n",
      "गंतिविधियों गंतिविधियों\n",
      "शासनाबद्दल शासनाबद्दल\n",
      "सर्वसंग्रह सर्वसंग्रह\n",
      "तुमच्यपैैकी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 400/400 [00:51<00:00,  7.80batch/s, loss=0.255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.35048904333263636; Train Accuracy = 56.19335937499999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 23.90batch/s, loss=1.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.3122028149664402; Validation Accuracy = 26.0986328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 21.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 20.5810546875\n",
      "देशभरामध्ये देशभरामध्ये\n",
      "पेशनधारियों पेशनधारियों\n",
      "अनुक्रमानुपतत अनुक्रमानुपात\n",
      "वाहिन्यांसाठीी वाहिन्यांसाठी\n",
      "लोकरचनाओं लोकरचनाओं\n",
      "ट्रां्क्रिप्रेश ट्रांसक्रिप्टेज़\n",
      "गंतिविधियों गंतिविधियों\n",
      "शशसनाबद्दल शासनाबद्दल\n",
      "सर्वसंग्रह सर्वसंग्रह\n",
      "तुमच्यापैकी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 400/400 [00:50<00:00,  7.89batch/s, loss=0.221]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.31643882423639297; Train Accuracy = 60.42578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 24.71batch/s, loss=1.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.3511207215487957; Validation Accuracy = 27.05078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 19.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 21.728515625\n",
      "देशारामध्येी देशभरामध्ये\n",
      "पेशनधारियों पेशनधारियों\n",
      "अनुक्रमानुपा अनुक्रमानुपात\n",
      "वाहिन्यांसाठी वाहिन्यांसाठी\n",
      "लोकरचनाओं लोकरचनाओं\n",
      "ट्रांसक्रिप्टज ट्रांसक्रिप्टेज़\n",
      "गंतिविधियों गंतिविधियों\n",
      "शासनाबद्दल शासनाबद्दल\n",
      "सर्वसंग्रह सर्वसंग्रह\n",
      "नुंच्यापीकी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 400/400 [00:50<00:00,  7.96batch/s, loss=0.253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.2845491870492697; Train Accuracy = 63.072265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 23.70batch/s, loss=1.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.366659875959158; Validation Accuracy = 27.2705078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 21.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 24.8046875\n",
      "देशभरााम्ये देशभरामध्ये\n",
      "पेशनधारियों पेशनधारियों\n",
      "अनुक्रमानुपा अनुक्रमानुपात\n",
      "वाहिन्यांसाठी वाहिन्यांसाठी\n",
      "लोकराचचां लोकरचनाओं\n",
      "ट्रांसक्रिप्ट ट्रांसक्रिप्टेज़\n",
      "गंतिविधियों गंतिविधियों\n",
      "शासनबबदददल शासनाबद्दल\n",
      "सर्वसंग्रह सर्वसंग्रह\n",
      "तुमच्यापैकी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 400/400 [00:50<00:00,  7.92batch/s, loss=0.162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.2553188585117459; Train Accuracy = 66.701171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 23.83batch/s, loss=1.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.4285310246050358; Validation Accuracy = 26.5380859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 19.84batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 25.732421875\n",
      "देशभरामध्ये देशभरामध्ये\n",
      "पेशनधारियों पेशनधारियों\n",
      "अनुक्रमानुप अनुक्रमानुपात\n",
      "वाहिन्यांसाठी वाहिन्यांसाठी\n",
      "लोकरचनाओं लोकरचनाओं\n",
      "ट्रांस्क्रिप्ट ट्रांसक्रिप्टेज़\n",
      "गगतिविधियों गंतिविधियों\n",
      "शासनाबद्दल शासनाबद्दल\n",
      "सर्वसंग्रह सर्वसंग्रह\n",
      "तुमच्यापैकी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 400/400 [00:50<00:00,  7.87batch/s, loss=0.146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.23686273459345103; Train Accuracy = 68.876953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 25.78batch/s, loss=1.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.430845219641924; Validation Accuracy = 26.6845703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 19.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 24.3896484375\n",
      "देशभाांध्ये देशभरामध्ये\n",
      "पेशखधारियों पेशनधारियों\n",
      "अनुक्रमानुपत अनुक्रमानुपात\n",
      "वाहिन्यांसाठी वाहिन्यांसाठी\n",
      "लोकरचनाओं लोकरचनाओं\n",
      "ट्रांसक्रिटट ट्रांसक्रिप्टेज़\n",
      "गान्तिवियों गंतिविधियों\n",
      "शासनबद्ददल शासनाबद्दल\n",
      "सर्वसंग्रह सर्वसंग्रह\n",
      "तुमच्यापैकी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 400/400 [00:50<00:00,  7.93batch/s, loss=0.15] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.22027455788105726; Train Accuracy = 69.396484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 22.08batch/s, loss=1.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.4701313748955727; Validation Accuracy = 27.7587890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 20.04batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 23.681640625\n",
      "देशभरामध्ये देशभरामध्ये\n",
      "पेशनधारियों पेशनधारियों\n",
      "अनुक्रमानुपतट अनुक्रमानुपात\n",
      "वाहिन्यांसाठी वाहिन्यांसाठी\n",
      "लोकरचनाओं लोकरचनाओं\n",
      "ट्रांसीक्रि्टट ट्रांसक्रिप्टेज़\n",
      "गंतिविधियों गंतिविधियों\n",
      "शासनाबद्दल शासनाबद्दल\n",
      "सर्वसंग्रह सर्वसंग्रह\n",
      "तुमच्यापैकी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    _, _, p, w = runner.train(i, 0.2)\n",
    "    runner.evaluate(); runner.inference()\n",
    "    for x, y in list(zip(p,w))[:10]:\n",
    "        print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 400/400 [00:50<00:00,  7.95batch/s, loss=0.247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.2603056246042252; Train Accuracy = 70.41796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 24.44batch/s, loss=1.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.4126202054321766; Validation Accuracy = 25.6591796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 20.18batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 23.388671875\n",
      "देशभरामध्ये देशभरामध्ये\n",
      "पेशनधारियों पेशनधारियों\n",
      "अनुक्रमाापत अनुक्रमानुपात\n",
      "वाहिन्यांसाठी वाहिन्यांसाठी\n",
      "लोकरचनाओं लोकरचनाओं\n",
      "ट्रांसक्रेप्टेज ट्रांसक्रिप्टेज़\n",
      "गंतिविधियों गंतिविधियों\n",
      "शासनाबद्दल शासनाबद्दल\n",
      "सर्वसंग्रह सर्वसंग्रह\n",
      "तुमच्यापैकी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 400/400 [00:50<00:00,  7.94batch/s, loss=0.149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.2532110440544784; Train Accuracy = 70.83203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 23.81batch/s, loss=1.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.3986054584383965; Validation Accuracy = 25.6591796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 20.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 21.5087890625\n",
      "देशभरममध्ये देशभरामध्ये\n",
      "पेशनधारियों पेशनधारियों\n",
      "अनुकर्मनुपपा अनुक्रमानुपात\n",
      "वाहिन्याससाठी वाहिन्यांसाठी\n",
      "लोकरचनाओं लोकरचनाओं\n",
      "ट्रांसक्रिप्टेज ट्रांसक्रिप्टेज़\n",
      "गंतिविधियों गंतिविधियों\n",
      "शासनाबद्दल शासनाबद्दल\n",
      "सर्वसंग्रह सर्वसंग्रह\n",
      "तुमच्यापीकी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 400/400 [00:50<00:00,  7.93batch/s, loss=0.202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.23348512791097165; Train Accuracy = 72.37890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 23.29batch/s, loss=1.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.4232169538736343; Validation Accuracy = 27.392578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 20.26batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 24.0234375\n",
      "देशभरामध्ये देशभरामध्ये\n",
      "पेशनधारियों पेशनधारियों\n",
      "अनुक्रमानुपाा अनुक्रमानुपात\n",
      "वाहिन्यांसाठी वाहिन्यांसाठी\n",
      "लोकरचनाओं लोकरचनाओं\n",
      "ट्रांसक्रिप्टेज ट्रांसक्रिप्टेज़\n",
      "गंतिविधियों गंतिविधियों\n",
      "शासनाबद्दल शासनाबद्दल\n",
      "सर्वसंग्रह सर्वसंग्रह\n",
      "तुमच्यापैकी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 400/400 [00:50<00:00,  7.92batch/s, loss=0.134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.22250628355890512; Train Accuracy = 72.87109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 24.48batch/s, loss=1.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.4810056686401367; Validation Accuracy = 25.537109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 18.96batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 21.38671875\n",
      "देशभरामध्ये देशभरामध्ये\n",
      "पेशनधारियों पेशनधारियों\n",
      "अनुक्रमानुपात अनुक्रमानुपात\n",
      "वाहिन्यांसाठी वाहिन्यांसाठी\n",
      "लोकरचनाओं लोकरचनाओं\n",
      "ट्रांसक्रिप्टेज ट्रांसक्रिप्टेज़\n",
      "गंतिविधियों गंतिविधियों\n",
      "शासनाबंदल शासनाबद्दल\n",
      "सर्वसंग्रह सर्वसंग्रह\n",
      "तुमच्यापैकीी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 400/400 [00:50<00:00,  7.93batch/s, loss=0.137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.21732615575194358; Train Accuracy = 73.162109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 24.21batch/s, loss=1.37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.4980301409959793; Validation Accuracy = 26.46484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 19.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 24.7802734375\n",
      "देशभरामध्ये देशभरामध्ये\n",
      "पेशनधााियों पेशनधारियों\n",
      "अनुक्रमानुपत अनुक्रमानुपात\n",
      "वाहिन्यांसाठी वाहिन्यांसाठी\n",
      "लोकरचनाओं लोकरचनाओं\n",
      "ट्रांसक्रिप्टेज ट्रांसक्रिप्टेज़\n",
      "गंतिविधियों गंतिविधियों\n",
      "शासनाबद्दल शासनाबद्दल\n",
      "सर्वसंग्रह सर्वसंग्रह\n",
      "तुमच्यापैकीी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 400/400 [00:50<00:00,  7.96batch/s, loss=0.192] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.19547440631315113; Train Accuracy = 74.89453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 24.44batch/s, loss=1.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.49997553601861; Validation Accuracy = 25.4638671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 20.59batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 23.7060546875\n",
      "देशभरामध्ये देशभरामध्ये\n",
      "पेशनधारियों पेशनधारियों\n",
      "अनुक्रमानुपात अनुक्रमानुपात\n",
      "वाहिन्यांसाठी वाहिन्यांसाठी\n",
      "लोकरचनाओं लोकरचनाओं\n",
      "ट्रांसक्रिप्टेज ट्रांसक्रिप्टेज़\n",
      "गंतिविधियों गंतिविधियों\n",
      "शासनाबद्दल शासनाबद्दल\n",
      "सर्वसंग्रह सर्वसंग्रह\n",
      "तुमच्यापैकी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 400/400 [00:52<00:00,  7.55batch/s, loss=0.141] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.1867413242906332; Train Accuracy = 75.255859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 16.84batch/s, loss=1.37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.5507164560258389; Validation Accuracy = 25.537109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 18.29batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 22.6806640625\n",
      "देशभरामध्ये देशभरामध्ये\n",
      "पेशनधारियों पेशनधारियों\n",
      "अनुक्रमानुपाात अनुक्रमानुपात\n",
      "वाहिन्यांसाठी वाहिन्यांसाठी\n",
      "लोकरच्ााओं लोकरचनाओं\n",
      "ट्रां्सक्रिप्टेज़ ट्रांसक्रिप्टेज़\n",
      "गंतिविधियों गंतिविधियों\n",
      "शासनाबद्दल शासनाबद्दल\n",
      "सर्वसंग्रह सर्वसंग्रह\n",
      "तुमच्यापैकी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 400/400 [00:54<00:00,  7.34batch/s, loss=0.142] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.17994348414242267; Train Accuracy = 75.78515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 20.42batch/s, loss=1.4] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.522559393197298; Validation Accuracy = 27.0263671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 18.19batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 23.779296875\n",
      "देशभरामध्ये देशभरामध्ये\n",
      "पेशनधारियों पेशनधारियों\n",
      "अनुक्रमानुपात अनुक्रमानुपात\n",
      "वाहिन्यांसाठी वाहिन्यांसाठी\n",
      "लोकरचनाओं लोकरचनाओं\n",
      "ट्रां्सकप्रिेट ट्रांसक्रिप्टेज़\n",
      "गंतिविधियों गंतिविधियों\n",
      "शासनाबद्दल शासनाबद्दल\n",
      "सर्वसंग्रह सर्वसंग्रह\n",
      "तुमच्यापैकी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 400/400 [00:53<00:00,  7.47batch/s, loss=0.14]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.17575067887082696; Train Accuracy = 76.6171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 20.91batch/s, loss=1.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.5403233207762241; Validation Accuracy = 27.685546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 16.80batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 24.31640625\n",
      "देशभरामध्ये देशभरामध्ये\n",
      "पेशनधारियों पेशनधारियों\n",
      "अनुक्रमानुपा अनुक्रमानुपात\n",
      "वाहिन्यांसाठी वाहिन्यांसाठी\n",
      "लोकरचनाओं लोकरचनाओं\n",
      "ट्रांसक््िपेेश ट्रांसक्रिप्टेज़\n",
      "गंत्विधियों गंतिविधियों\n",
      "शासनाबद्दल शासनाबद्दल\n",
      "सर्वसंग्रह सर्वसंग्रह\n",
      "तुमच्यापैकी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 400/400 [00:50<00:00,  7.88batch/s, loss=0.197] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.1637278700247407; Train Accuracy = 76.87890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 24.71batch/s, loss=1.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.5660292208194733; Validation Accuracy = 26.07421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 20.88batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 23.53515625\n",
      "देशभरामध्ये देशभरामध्ये\n",
      "पेशनधारियों पेशनधारियों\n",
      "अनुक्रमानुपात अनुक्रमानुपात\n",
      "वाहिन्यांसाठी वाहिन्यांसाठी\n",
      "लोकरचनाओं लोकरचनाओं\n",
      "ट्रांसक्रप््टेज़ ट्रांसक्रिप्टेज़\n",
      "गंतिविधियों गंतिविधियों\n",
      "शासनाबद्दल शासनाबद्दल\n",
      "सर्वसंग्रह सर्वसंग्रह\n",
      "तुमच्यापैकी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    _, _, p, w = runner.train(i, 0.)\n",
    "    runner.evaluate(); runner.inference()\n",
    "    for x, y in list(zip(p,w))[:10]:\n",
    "        print(x,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
