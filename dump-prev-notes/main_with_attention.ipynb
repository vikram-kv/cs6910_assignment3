{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS6910 Assignment 3 (RNN Frameworks for transliteration) - With Bahdanau attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries for the notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# set the device to 'cuda' if available\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# define the source and target languages\n",
    "TARGET = 'hin'\n",
    "SOURCE = 'eng'\n",
    "# define the special tokens that stand for start of seq, end of seq, \n",
    "# an unknown symbol.\n",
    "SOS_SYM = '@'\n",
    "EOS_SYM = '$'\n",
    "UNK_SYM = '!'\n",
    "# define a special token for padding - this helps with batch processing \n",
    "PAD_SYM = '%'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Functions and Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load the 'cat' (= train/val/test) data of language 'lang'\n",
    "def load_data(lang, cat):\n",
    "    fcontents = open(f'aksharantar_sampled/{lang}/{lang}_{cat}.csv','r', encoding='utf-8').readlines()\n",
    "    pairs = [tuple(l.strip().split(',')) for l in fcontents]\n",
    "    x_data, y_data = list(map(list,zip(*pairs)))\n",
    "    return x_data, y_data\n",
    "\n",
    "# class for a language with useful functions.\n",
    "class Language:\n",
    "    def __init__(self, name):\n",
    "        self.lname = name\n",
    "    \n",
    "    # function to create the vocabulary(set of tokens) using the words in 'data'\n",
    "    # here, a token is either a special token or a lang character\n",
    "    def create_vocabulary(self, *data):\n",
    "        symbols = set()\n",
    "        for wd in data:\n",
    "            for c in wd:\n",
    "                symbols.add(c)\n",
    "        self.symbols = symbols\n",
    "    \n",
    "    # function to generate the index2sym (a number to a token) and \n",
    "    # sym2index (a token to a number) mappings using the vocabulary\n",
    "    def generate_mappings(self):\n",
    "        self.index2sym = {0: SOS_SYM, 1 : EOS_SYM, 2 : UNK_SYM, 3 : PAD_SYM}\n",
    "        self.sym2index = {SOS_SYM : 0, EOS_SYM : 1, UNK_SYM : 2, PAD_SYM : 3}\n",
    "        self.symbols = list(self.symbols)\n",
    "        self.symbols.sort()\n",
    "\n",
    "        for i, sym in enumerate(self.symbols):\n",
    "            self.sym2index[sym] = i + 4\n",
    "            self.index2sym[i+4] = sym\n",
    "        \n",
    "        self.num_tokens = len(self.index2sym.keys())\n",
    "    \n",
    "    # function to tokenize a word and convert all the tokens to\n",
    "    # their corr. numbers using sym2index\n",
    "    def convert_to_numbers(self, word):\n",
    "        enc = [self.sym2index[SOS_SYM]]\n",
    "        for ch in word:\n",
    "            if ch in self.sym2index.keys():\n",
    "                enc.append(self.sym2index[ch])\n",
    "            else:\n",
    "                enc.append(self.sym2index[UNK_SYM])\n",
    "        enc.append(self.sym2index[EOS_SYM])\n",
    "        return enc\n",
    "    \n",
    "    # convert a list of predictions (each prediction is a list of numbers)\n",
    "    # to the corresponding list of words using index2sym\n",
    "    # pred should be numpy array of shape (number_of_words, max_word_length)\n",
    "    # tokens after EOS_SYM are discarded\n",
    "    def convert_to_words(self, preds):\n",
    "        num = preds.shape[0]\n",
    "        words = [] \n",
    "        for i in range(num):\n",
    "            wd = ''\n",
    "            for idx in preds[i][1:]: # 1: -> ignore SOS token\n",
    "                ch = self.index2sym[idx]\n",
    "                if ch != EOS_SYM:\n",
    "                    wd += ch\n",
    "            words.append(wd)\n",
    "        return words\n",
    "\n",
    "    # get the number assigned to a token\n",
    "    def get_index(self, sym):\n",
    "        return self.sym2index[sym]\n",
    "    \n",
    "    # get the number of tokens in the vocabulary\n",
    "    def get_size(self):\n",
    "        return self.num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples = 51200\n",
      "Number of valid samples = 4096\n",
      "Number of test samples = 4096\n"
     ]
    }
   ],
   "source": [
    "# load all the available data and print sample counts for each set\n",
    "x_train, y_train = load_data(TARGET, 'train')\n",
    "x_valid, y_valid = load_data(TARGET, 'valid')\n",
    "x_test, y_test = load_data(TARGET, 'test')\n",
    "\n",
    "print(f'Number of train samples = {len(x_train)}')\n",
    "print(f'Number of valid samples = {len(x_valid)}')\n",
    "print(f'Number of test samples = {len(x_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Vocabulary Size = 26\n",
      "Source Vocabulary = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Source Mapping {0: '@', 1: '$', 2: '!', 3: '%', 4: 'a', 5: 'b', 6: 'c', 7: 'd', 8: 'e', 9: 'f', 10: 'g', 11: 'h', 12: 'i', 13: 'j', 14: 'k', 15: 'l', 16: 'm', 17: 'n', 18: 'o', 19: 'p', 20: 'q', 21: 'r', 22: 's', 23: 't', 24: 'u', 25: 'v', 26: 'w', 27: 'x', 28: 'y', 29: 'z'}\n",
      "Target Vocabulary Size = 64\n",
      "Target Vocabulary = ['ँ', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ऑ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'ळ', 'व', 'श', 'ष', 'स', 'ह', '़', 'ऽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॅ', 'े', 'ै', 'ॉ', 'ो', 'ौ', '्']\n",
      "Target Mapping {0: '@', 1: '$', 2: '!', 3: '%', 4: 'ँ', 5: 'ं', 6: 'ः', 7: 'अ', 8: 'आ', 9: 'इ', 10: 'ई', 11: 'उ', 12: 'ऊ', 13: 'ऋ', 14: 'ए', 15: 'ऐ', 16: 'ऑ', 17: 'ओ', 18: 'औ', 19: 'क', 20: 'ख', 21: 'ग', 22: 'घ', 23: 'ङ', 24: 'च', 25: 'छ', 26: 'ज', 27: 'झ', 28: 'ञ', 29: 'ट', 30: 'ठ', 31: 'ड', 32: 'ढ', 33: 'ण', 34: 'त', 35: 'थ', 36: 'द', 37: 'ध', 38: 'न', 39: 'प', 40: 'फ', 41: 'ब', 42: 'भ', 43: 'म', 44: 'य', 45: 'र', 46: 'ल', 47: 'ळ', 48: 'व', 49: 'श', 50: 'ष', 51: 'स', 52: 'ह', 53: '़', 54: 'ऽ', 55: 'ा', 56: 'ि', 57: 'ी', 58: 'ु', 59: 'ू', 60: 'ृ', 61: 'ॅ', 62: 'े', 63: 'ै', 64: 'ॉ', 65: 'ो', 66: 'ौ', 67: '्'}\n"
     ]
    }
   ],
   "source": [
    "# create language objects for storing vocabulary, index2sym and sym2index\n",
    "SRC_LANG = Language(SOURCE)\n",
    "TAR_LANG = Language(TARGET)\n",
    "\n",
    "# creating vocabulary using train data only\n",
    "SRC_LANG.create_vocabulary(*(x_train))\n",
    "TAR_LANG.create_vocabulary(*(y_train))\n",
    "\n",
    "# otherwise, use unicode characters (assigned codepoints) in the script's range\n",
    "# src_lang.create_vocabulary_range()\n",
    "# tar_lang.create_vocabulary_range()\n",
    "\n",
    "# generate mappings from characters to numbers and vice versa\n",
    "SRC_LANG.generate_mappings()\n",
    "TAR_LANG.generate_mappings()\n",
    "\n",
    "# print the source and target vocabularies\n",
    "print(f'Source Vocabulary Size = {len(SRC_LANG.symbols)}')\n",
    "print(f'Source Vocabulary = {SRC_LANG.symbols}')\n",
    "print(f'Source Mapping {SRC_LANG.index2sym}')\n",
    "print(f'Target Vocabulary Size = {len(TAR_LANG.symbols)}')\n",
    "print(f'Target Vocabulary = {TAR_LANG.symbols}')\n",
    "print(f'Target Mapping {TAR_LANG.index2sym}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Dataset class to help with creating the dataset. Converts the data into numbers\n",
    "# using the source and target languages' sym2index and index2sym dictionaries\n",
    "class TransliterateDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data, src_lang : Language, tar_lang : Language):\n",
    "        # save all the data points and the language objects\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        self.src_lang = src_lang\n",
    "        self.tar_lang = tar_lang\n",
    "        \n",
    "    def __len__(self):\n",
    "        # needs to be implemented for a pytorch `Dataset`\n",
    "        return len(self.y_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # gives the data point (X, y) at index = idx\n",
    "        # we convert them to a tensor of numbers using the Language objects\n",
    "        # also returns the word y for ease of computing accuracy later\n",
    "        x_enc, y_enc = self.x_data[idx], self.y_data[idx]\n",
    "        x_enc = self.src_lang.convert_to_numbers(x_enc)\n",
    "        y_enc = self.tar_lang.convert_to_numbers(y_enc) \n",
    "        return torch.tensor(x_enc, dtype=int), torch.tensor(y_enc,dtype=int), self.y_data[idx]\n",
    "\n",
    "# This is a collation function for post-processing a batch in a DataLoader. We sort the instances (X,y) in a batch\n",
    "# based on seq length of X in desc order and create a padded batch to help with batch-processing in recurrent\n",
    "# networks\n",
    "class CollationFunction:\n",
    "    def __init__(self, src_lang : Language, tar_lang : Language):\n",
    "        self.src_lang = src_lang\n",
    "        self.tar_lang = tar_lang\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        # reasoning : https://stackoverflow.com/questions/51030782/why-do-we-pack-the-sequences-in-pytorch\n",
    "        batch.sort(key = lambda x : len(x[0]), reverse=True)\n",
    "        src, tar, tar_words = zip(*batch)\n",
    "        src_lens = torch.tensor([len(x) for x in src], dtype=int)\n",
    "        # pad both the X part(src) and y part(tar) with PAD_SYM\n",
    "        src = nn.utils.rnn.pad_sequence(list(src), batch_first=True, padding_value=self.src_lang.get_index(PAD_SYM))\n",
    "        tar = nn.utils.rnn.pad_sequence(list(tar), batch_first=True, padding_value=self.tar_lang.get_index(PAD_SYM))\n",
    "        # return padded batch_X (src), padded batch_Y (tar), X_lens (needed for unpacking) and y words(tar_words)\n",
    "        # each entry in tar_words is a string\n",
    "        return src, tar, src_lens, tar_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Class for the Encoder Network\n",
    "'''\n",
    "class EncoderNet(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_layers, hid_size, cell_type, \n",
    "                 bidirect=False, dropout=0):\n",
    "        '''\n",
    "            input_vocab_size (V) = number of tokens in the input language dictionary\n",
    "            embed_size = dim of embedding for each input token\n",
    "            num_layers = number of layers in the encoder network\n",
    "            hidden_size = dim of hidden state of each cell\n",
    "            cell_type = RNN/GRU/LSTM\n",
    "            bidirect = True for bidirectional network and False otherwise\n",
    "            dropout = dropout probability\n",
    "        '''\n",
    "        # save all the necessary arch information\n",
    "        super(EncoderNet, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hid_size\n",
    "        self.embed_size = embed_size\n",
    "        self.num_layers = num_layers\n",
    "        self.cell_type = cell_type\n",
    "        self.bidirect = bidirect\n",
    "\n",
    "        # create the embedding layer and a dropout layer for it\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embed_size)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # we create the kw args using the received parameters and use it to create network layer stack\n",
    "        kwargs = {'input_size':embed_size, 'hidden_size':hid_size, 'num_layers':num_layers, \n",
    "                 'bidirectional':bidirect, 'batch_first':True}\n",
    "        if num_layers > 1:\n",
    "            kwargs['dropout'] = dropout\n",
    "        if cell_type == 'RNN':\n",
    "            self.network = nn.RNN(**kwargs)\n",
    "        elif cell_type == 'LSTM':\n",
    "            self.network = nn.LSTM(**kwargs)\n",
    "        else:\n",
    "            self.network = nn.GRU(**kwargs)\n",
    "        \n",
    "        # for combining the final layer's forward and reverse directions' final hidden state\n",
    "        # we create linear layers to do this for each encoder layer\n",
    "        if (self.bidirect):\n",
    "            self.combine_forward_backward = [nn.Linear(2 * hid_size, hid_size) for _ in range(num_layers)]\n",
    "            self.combine_forward_backward = nn.ModuleList(self.combine_forward_backward)\n",
    "\n",
    "    def forward(self, batch_X, X_lens):\n",
    "        '''\n",
    "            batch_X - padded input batch of examples. shape = (batch_size, max_batch_seq_length)\n",
    "                      [padding is already taken care of by collate function of DataLoader]\n",
    "            X_lens - length of each input sequence. A python list of `batch_size` many integers\n",
    "        '''\n",
    "        # pass the batch through the embedding with dropout and pack the batch.\n",
    "        # packing is for efficiency \n",
    "        batch_X = self.embedding(batch_X)\n",
    "        batch_X = self.dropout(batch_X)\n",
    "        packed_batch_x = nn.utils.rnn.pack_padded_sequence(batch_X, lengths=X_lens, batch_first=True, \n",
    "                                                           enforce_sorted=True)\n",
    "        # send the batch through the network correctly based on cell type\n",
    "        # packed_outputs = packed sequence of outputs from the final layer.\n",
    "        # hidden_outputs = hidden outputs from every layer. shape = (D * num_layers, batch_size, hidden_size)\n",
    "        # D = 2 if bidirectional; else 1\n",
    "        if self.cell_type == 'LSTM':\n",
    "            packed_outputs, (hidden_outputs, _) = self.network(packed_batch_x)\n",
    "        else:\n",
    "            packed_outputs, hidden_outputs = self.network(packed_batch_x)\n",
    "        \n",
    "        # unpack the packed sequence. outputs has shape (batch_size, max_seq_len, D * hidden_size)\n",
    "        # without attention, outputs is NOT USED.\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs, batch_first=True)\n",
    "\n",
    "        # shape of `hidden_state_all_layers`= (num_layers, batch_size, hidden_size)\n",
    "        hidden_state_all_layers = hidden_outputs[:, :, :]\n",
    "        if self.bidirect:\n",
    "            # here, we need to process bidirectional final hidden states of each layer through a linear layer\n",
    "            req_shape = (hidden_outputs.shape[0]//2, hidden_outputs.shape[1], hidden_outputs.shape[2])\n",
    "            hidden_state_all_layers = torch.zeros(req_shape).to(device)\n",
    "            for i in range(self.num_layers):\n",
    "                xidx = 2 * i\n",
    "                # concatenate the forward and reverse directions outputs along the hidden_size's dimension\n",
    "                # shape = (batch_size, 2 * hidden_size) now\n",
    "                concat_hidden_state_cur_layer = torch.cat([hidden_outputs[xidx, :, :], hidden_outputs[xidx + 1, :, :]], dim=1)\n",
    "                hidden_state_cur_layer = self.combine_forward_backward[i](concat_hidden_state_cur_layer)\n",
    "                hidden_state_cur_layer = torch.tanh(hidden_state_cur_layer)\n",
    "                hidden_state_all_layers[i, :, :] = hidden_state_cur_layer\n",
    "\n",
    "        # outputs - shape (batch_size, max_seq_len, D * hidden_size) -> NOT USED without attention\n",
    "        # hidden_state_all_layers - shape (num_layers, batch_size, hidden_size)\n",
    "        return outputs, hidden_state_all_layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Class for Attention\n",
    "'''\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim, bidirect = False):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bidirect = bidirect\n",
    "        self.attn_matrix_indim = 3 * hidden_dim if bidirect == True else 2 * hidden_dim\n",
    "        self.U = nn.Linear(self.attn_matrix_indim, hidden_dim) # to be sent to tanh layer\n",
    "        self.V = nn.Linear(self.hidden_dim, 1, bias=False) # dotted with tanh layer's output to get weights\n",
    "        self.softmaxlayer = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, prev_dec_hidden, padded_enc_outputs, mask):\n",
    "        ''' \n",
    "            prev_dec_hidden -> shape (batch_size, hidden_size) - first decoder layer's hidden state\n",
    "            padded_enc_outputs -> shape (batch_size, max_seq_len, hidden_size)\n",
    "            mask -> shape (batch_size, max_seq_len) with 1 in locations where pad token is present\n",
    "            max_seq_len = max_seq_len in batch_X [that was processed by encoder]\n",
    "        '''\n",
    "        batch_size, max_seq_len = padded_enc_outputs.shape\n",
    "        hidden_extended = prev_dec_hidden.unsqueeze(1).repeat(1, max_seq_len, 1)\n",
    "        # hidden_extended shape = (batch_size, max_seq_len, hidden_size)\n",
    "        U_input = torch.cat([hidden_extended, padded_enc_outputs], dim=2).to(device)\n",
    "        # U_input shape = (batch_size, max_seq_len, [2 or 3] * hidden_size)\n",
    "        tanh_output = torch.tanh(self.U(U_input))\n",
    "        # tanh_output shape = (batch_size, max_seq_len, hidden_size)\n",
    "        attn_weights = self.V(tanh_output).squeeze(2)\n",
    "        # attn_weights shape = (batch_size, max_seq_len)\n",
    "        attn_weights = torch.masked_fill(attn_weights, mask==1, -1e12)\n",
    "        # fill pad locations with very small values to be zeroed by softmax\n",
    "        attn_weights = self.softmaxlayer(attn_weights)\n",
    "        # convert weights to probabilities over max_seq_length dimension\n",
    "        return attn_weights\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Class for the Decoder Network\n",
    "'''\n",
    "class DecoderNet(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_layers, hid_size, cell_type, attention,\n",
    "                 dropout=0, enc_bidirect=False):\n",
    "        super(DecoderNet, self).__init__()\n",
    "        # store all the network arch information\n",
    "        self.hidden_size = hid_size\n",
    "        self.embed_size = embed_size\n",
    "        self.num_layers = num_layers\n",
    "        self.vocab_size = vocab_size\n",
    "        self.cell_type = cell_type\n",
    "        # create the embedding layer with a dropout layer for it\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        # create the linear layer for producing output logits (need to be sent through softmax to get \n",
    "        # char probabilities). But, we can use CrossEntropyLoss() on this logits directly\n",
    "        self.out_layer = nn.Linear(hid_size, vocab_size)\n",
    "\n",
    "       # we create the required architecture using the received parameters\n",
    "       # now, input_size will be [embed_size + 2 * hidden_size] if enc_bidirect\n",
    "       #                    and [embed_size + hidden_size] otherwise\n",
    "        kwargs = {'hidden_size':hid_size, 'num_layers':num_layers, \n",
    "                 'batch_first':True}\n",
    "        kwargs['input_size'] = embed_size + 2 * hid_size if enc_bidirect else embed_size + hid_size\n",
    "        # create the network using kwargs\n",
    "        if num_layers > 1:\n",
    "            kwargs['dropout'] = dropout\n",
    "        if cell_type == 'RNN':\n",
    "            self.network = nn.RNN(**kwargs)\n",
    "        elif cell_type == 'LSTM':\n",
    "            self.network = nn.LSTM(**kwargs)\n",
    "        else:\n",
    "            self.network = nn.GRU(**kwargs)\n",
    "        \n",
    "        # save the attention object\n",
    "        self.attention = attention\n",
    "\n",
    "    # will always go 1 step forward in time (seqlen = L = 1)\n",
    "    def forward(self, batch_y, prev_decoder_state, padded_enc_outputs, mask):\n",
    "        ''' \n",
    "            batch_y -> shape (batch_size) = decoder input with vocabulary indices from target language\n",
    "            prev_decoder_state(RNN, GRU) -> shape (num_layers, batch_size, hidden_size) \n",
    "            prev_decoder_state(LSTM) -> tuple of prev_hidden_state, prev_cell_state\n",
    "                                        both have shape (num_layers, batch_size, hidden_size) ()\n",
    "            padded_enc_outputs -> shape (batch_size, max_enc_seq_len, (2 or 1) * hid_size)\n",
    "                                        2 if encoder is bidirectional\n",
    "            mask -> shape (batch_size, max_enc_seq_len) -> 1 where pad token is present\n",
    "        '''\n",
    "        # we add a dummy dimension for seqlen = 1. new shape of batch_y is (batch_size, 1)\n",
    "        batch_y = batch_y.unsqueeze(1)\n",
    "\n",
    "        # pass through embedding and dropout layers. new shape of batch_y is (batch_size, 1, hidden_size)\n",
    "        embedded_batch_y = self.embedding(batch_y)\n",
    "        embedded_batch_y = self.dropout(embedded_batch_y)\n",
    "\n",
    "        # unpack the decoder state and compute attention\n",
    "        if self.cell_type == 'LSTM':\n",
    "            decoder_hidden_state, _ = prev_decoder_state\n",
    "        else:\n",
    "            decoder_hidden_state = prev_decoder_state\n",
    "\n",
    "        attn_weights = self.attention(decoder_hidden_state[0, :, :], padded_enc_outputs, mask)\n",
    "        # recall attn_weights shape = (batch_size, max_enc_seq_len)\n",
    "        attn_weights = attn_weights.unsqueeze(1)\n",
    "        attn_weighted_enc_outputs = torch.bmm(attn_weights, padded_enc_outputs)\n",
    "        # attn_weighted_enc_outputs shape = (batch_size, 1, (2 or 1) * hid_size)\n",
    "\n",
    "        dec_input = torch.cat([attn_weighted_enc_outputs, embedded_batch_y], dim=2)\n",
    "        # dec_input shape (batch_size, 1, (2 or 1) * hid_size + embed_size)\n",
    "\n",
    "        # pass dec_input through the network\n",
    "        outputs, new_decoder_state = self.network(dec_input, prev_decoder_state)\n",
    "        outputs = outputs.squeeze(1) # remove seqlen dimension. shape = (batch_size, hidden_size)\n",
    "        # pass outputs through the linear layer to get the logits (shape = (batch_size, out_vocab_size))\n",
    "        logits = self.out_layer(outputs)\n",
    "        # attention weights is required for visualiztion\n",
    "        return logits, new_decoder_state, attn_weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq(Encoder-Decoder) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Class for encapsulating the encoder and decoder networks\n",
    "'''\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder :EncoderNet, decoder : DecoderNet, src_lang : Language, tar_lang : Language) -> None:\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        # store the encoder and decoder along with language objects in the class\n",
    "        self.enc_model = encoder\n",
    "        self.dec_model = decoder\n",
    "        self.src_lang = src_lang\n",
    "        self.tar_lang = tar_lang\n",
    "        self.cell_type = self.dec_model.cell_type\n",
    "        # we require num of enc layers == num of dec layers as we connect encoder and decoder\n",
    "        # layer by layer\n",
    "        assert(self.enc_model.num_layers == self.dec_model.num_layers)\n",
    "        self.num_layers = self.enc_model.num_layers\n",
    "    \n",
    "    # function to make mask for batch_X where mask == 1 iff pad token is present in that location\n",
    "    def make_mask(self, batch_X):\n",
    "        return torch.where(batch_X == self.tar_lang.sym2index[PAD_SYM], 1, 0)\n",
    "    \n",
    "    def forward(self, batch_X, batch_y, X_lens, tf_ratio=None):\n",
    "        ''' \n",
    "            batch_X -> shape (batch_size, max_batch_X_seq_len) - padded input to encoder\n",
    "            batch_y -> shape (batch_size, max_batch_y_seq_len) - padded input to decoder\n",
    "            X_lens -> list of true (unpadded) lengths of the sequences in batch_X\n",
    "        '''\n",
    "        # compute batch_size and send batch_X through the encoder\n",
    "        batch_size = batch_X.size(0)\n",
    "        enc_outputs, final_enc_hidden_state = self.enc_model(batch_X, X_lens)\n",
    "        # recall final_enc_hidden_state -> shape (num_layers, batch_size, hidden_size)\n",
    "        \n",
    "        # make padding mask for batch_X\n",
    "        pad_mask = self.make_mask(batch_X)\n",
    "        tarlength = batch_y.size(1) # max seq length of batch_y\n",
    "\n",
    "        # outlogits -> tensor for storing the output logits (softmax to get post prob.)\n",
    "        outlogits = torch.zeros(batch_size, tarlength, self.dec_model.vocab_size).to(device)\n",
    "        # preds -> tensor for storing argmax(logits) over the target vocab for each example and each time step\n",
    "        preds = torch.zeros(batch_size, tarlength).to(device)\n",
    "\n",
    "        dec_input = batch_y[:,0] # get initial input for decoder -> SOS tokens with shape (batch_size)\n",
    "        decoder_state = final_enc_hidden_state # initially decoder hidden state = final_enc_hidden_state\n",
    "\n",
    "        if (self.cell_type == 'LSTM'):\n",
    "            # for LSTM, cell state is initialized to zero and is added to decoder state\n",
    "            init_dec_cell_state = torch.zeros_like(decoder_state, device = device)\n",
    "            decoder_state = (decoder_state, init_dec_cell_state)\n",
    "        \n",
    "        # for each timestep\n",
    "        for tstep in range(1, tarlength):\n",
    "            # send the dec_input through the decoder. we ignore the attn_weights here.\n",
    "            curlogits, decoder_state, _ = self.dec_model(dec_input, decoder_state, enc_outputs, pad_mask)\n",
    "            # recall curlogits -> shape (batch_size, out_vocab_size); decoder_state -> shape invariant.\n",
    "            tf_input = batch_y[:, tstep] # dec input for next time step if teacher forcing is chosen\n",
    "            # pred -> argmax along vocab_size (dim = 1) to get class labels. shape = (batch_size)\n",
    "            pred = torch.argmax(curlogits, dim=1).to(device)\n",
    "            # greedy dec input is whatever set of words was predicted previously. shape = (batch_size)\n",
    "            dec_input = pred\n",
    "            # change dec input to tf input with prob = tf_ratio\n",
    "            if tf_ratio != None and torch.rand(1)[0] < tf_ratio:\n",
    "                dec_input = tf_input\n",
    "            # store curlogits (for loss backprop) and pred (for predicted word construction)\n",
    "            # for the current timestep\n",
    "            outlogits[:, tstep, :] = curlogits \n",
    "            preds[:, tstep] = pred\n",
    "        # NOTE - outlogits[:, 0, :] -> is a dummy tensor. should be discarded in loss computation\n",
    "        # Similarly preds[:, 0] -> is also to be ignored. It has only 0s (=SOS_SYM).\n",
    "        return outlogits, preds\n",
    "\n",
    "    ### incomplete here onwards...\n",
    "    def inference_forward(self, batch_X, X_lens, max_dec_length=25):\n",
    "        ''' \n",
    "            batch_X -> shape (batch_size, max_batch_X_seq_len) - padded input to encoder\n",
    "            X_lens -> list of true (unpadded) lengths of the sequences in batch_X\n",
    "            max_dec_length -> length beyond which decoding is stopped\n",
    "        '''\n",
    "        # compute batch_size and send batch_X through the encoder\n",
    "        batch_size = batch_X.size(0)\n",
    "        _, final_enc_hidden_state = self.enc_model(batch_X, X_lens)\n",
    "        # recall final_enc_hidden_state -> shape (num_layers, batch_size, hidden_size)\n",
    "        \n",
    "        # outlogits -> tensor for storing the output logits (softmax to get post prob.)\n",
    "        outlogits = torch.zeros(batch_size, max_dec_length, self.dec_model.vocab_size).to(device)\n",
    "        # preds -> tensor for storing argmax(logits) over the target vocab for each example at each time step\n",
    "        preds = torch.zeros(batch_size, max_dec_length).to(device)\n",
    "        dec_input = torch.tensor([self.tar_lang.sym2index[SOS_SYM] for _ in range(batch_size)], device=device)\n",
    "        # get initial input for decoder -> SOS tokens with shape (batch_size)\n",
    "        decoder_state = final_enc_hidden_state # initially decoder hidden state = final_enc_hidden_state\n",
    "\n",
    "        if (self.cell_type == 'LSTM'):\n",
    "            # for LSTM, cell state is initialized to zero and is added to decoder state\n",
    "            init_dec_cell_state = torch.zeros_like(decoder_state, device = device)\n",
    "            decoder_state = (decoder_state, init_dec_cell_state)\n",
    "\n",
    "        # for each timestep\n",
    "        for tstep in range(1, max_dec_length):\n",
    "            # send the dec_input through the decoder.\n",
    "            curlogits, decoder_state = self.dec_model(dec_input, decoder_state)\n",
    "            # recall curlogits -> shape (batch_size, out_vocab_size); decoder_state -> shape invariant.\n",
    "            # pred -> argmax along vocab_size (dim = 1) to get class labels. shape = (batch_size)\n",
    "            pred = torch.argmax(curlogits, dim=1).to(device)\n",
    "            # greedy dec input is whatever set of words was predicted previously. shape = (batch_size)\n",
    "            dec_input = pred\n",
    "            # store curlogits and pred (for predicted word construction) for the current timestep\n",
    "            outlogits[:, tstep, :] = curlogits \n",
    "            preds[:, tstep] = pred\n",
    "\n",
    "        # generate predicted words using preds tensor and return it.\n",
    "        pred_words = self.tar_lang.convert_to_words(preds.cpu().numpy())\n",
    "        return pred_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Evaluation/Inference Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner():\n",
    "    def __init__(self, src_lang : Language, tar_lang : Language, common_embed_size, common_num_layers, \n",
    "                 common_hidden_size, common_cell_type, enc_bidirect, dropout, opt_name='Adam',\n",
    "                 learning_rate=1e-3):\n",
    "        # save the language objects\n",
    "        self.src_lang = src_lang\n",
    "        self.tar_lang = tar_lang\n",
    "\n",
    "        # create all the sub-networks and the main model\n",
    "        self.encoder = EncoderNet(vocab_size=src_lang.get_size(), embed_size=common_embed_size,\n",
    "                             num_layers=common_num_layers, hid_size=common_hidden_size,\n",
    "                             cell_type= common_cell_type, bidirect=enc_bidirect, dropout=dropout)\n",
    "        self.decoder = DecoderNet(vocab_size=tar_lang.get_size(), embed_size=common_embed_size,\n",
    "                             num_layers=common_num_layers, hid_size=common_hidden_size,\n",
    "                             cell_type=common_cell_type, dropout=dropout)\n",
    "        self.model = EncoderDecoder(encoder=self.encoder, decoder=self.decoder, src_lang=src_lang, \n",
    "                                    tar_lang=tar_lang)\n",
    "        \n",
    "        # move model to the torch device\n",
    "        self.model.to(device)\n",
    "        # for reproducibility - seed everything with 42\n",
    "        torch.manual_seed(42); torch.cuda.manual_seed(42); np.random.seed(42); random.seed(42)\n",
    "\n",
    "        self.model.apply(self.init_weights) # initialize model weights\n",
    "\n",
    "        # initialize the data loaders\n",
    "        self.trainLoader, self.validLoader, self.testLoader = None, None, None\n",
    "\n",
    "        # optimizer for the model and loss function [that ignores locs where target = PAD token]\n",
    "        self.optimizer = None\n",
    "        self.loss_criterion = nn.CrossEntropyLoss(ignore_index=tar_lang.sym2index[PAD_SYM])\n",
    "        if opt_name == 'Adam':\n",
    "            self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        '''\n",
    "        function to initialize the weights of the model parameters\n",
    "        '''\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.normal_(param.data, mean=0, std=0.05)\n",
    "            else:\n",
    "                nn.init.constant_(param.data, 0)\n",
    "    \n",
    "    def generate_data_loaders(self, data_X, data_y, batch_size):\n",
    "        '''\n",
    "        Create the pytorch Dataset and use it to make the dataloader. The dataloader\n",
    "        post-processes every batch to add padding\n",
    "        '''\n",
    "        dataset = TransliterateDataset(data_X, data_y, src_lang=SRC_LANG, tar_lang=TAR_LANG)\n",
    "        dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                                collate_fn=CollationFunction(SRC_LANG, TAR_LANG))\n",
    "        return dataloader\n",
    "\n",
    "    def make_all_loaders(self, train_data, valid_data, test_data, batch_size):\n",
    "        ''' \n",
    "        get train, valid, test data and create dataloaders of batches with size=batch_size\n",
    "        '''\n",
    "        train_X, train_y = train_data\n",
    "        valid_X, valid_y = valid_data\n",
    "        test_X, test_y = test_data\n",
    "\n",
    "        self.trainLoader = self.generate_data_loaders(train_X, train_y, batch_size)\n",
    "        self.validLoader = self.generate_data_loaders(valid_X, valid_y, batch_size)\n",
    "        self.testLoader = self.generate_data_loaders(test_X, test_y, batch_size)\n",
    "\n",
    "    def get_accuracy(self, pred_words, tar_words):\n",
    "        ''' \n",
    "        compute the accuracy using (predicted words, target words) and return it.\n",
    "        exact word matching is used.\n",
    "        '''\n",
    "        assert(len(pred_words) == len(tar_words))\n",
    "        count = 0\n",
    "        for i in range(len(pred_words)):\n",
    "            if pred_words[i] == tar_words[i]:\n",
    "                count += 1\n",
    "        return count / len(pred_words)\n",
    "\n",
    "    def train(self, epoch_number, tf_ratio=0.6):\n",
    "        '''\n",
    "        train the model for 1 epoch with teacher forcing ratio = tf_ratio.\n",
    "        epoch_number is displayed in the output\n",
    "        '''\n",
    "        # sanity checks \n",
    "        assert(self.trainLoader != None); assert(self.optimizer != None)\n",
    "\n",
    "        # set model in training mode for autograd to be activated\n",
    "        self.model.train(); self.optimizer.zero_grad()\n",
    "        # maintain training loss and lists of predicted and true words\n",
    "        train_loss = 0.0\n",
    "        pred_words, true_words = [], []\n",
    "        with tqdm(self.trainLoader, unit=' batch') as tqdmLoader:\n",
    "            for batch_X, batch_y, X_lens, y_words in tqdmLoader:\n",
    "                tqdmLoader.set_description(f'Epoch {epoch_number}')\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                # get the logits, preds for the current batch\n",
    "                logits, preds = self.model(batch_X, batch_y, X_lens, tf_ratio=tf_ratio)\n",
    "                # ignore loss for the first time step\n",
    "                targets = batch_y[:, 1:]; logits = logits[:, 1:, :]\n",
    "                logits = logits.swapaxes(1, 2) # make class logits the second dimension as needed\n",
    "                loss = self.loss_criterion(logits, targets); loss.backward(); train_loss += loss.item()\n",
    "                self.optimizer.step(); self.optimizer.zero_grad()\n",
    "                batch_pred_words = self.tar_lang.convert_to_words(preds.cpu().numpy())\n",
    "                tqdmLoader.set_postfix(loss=loss.item())\n",
    "                true_words += y_words; pred_words += batch_pred_words\n",
    "        train_loss /= len(self.trainLoader); train_acc = self.get_accuracy(pred_words, true_words)\n",
    "        print(f'Train Loss = {train_loss}; Train Accuracy = {train_acc * 100}')\n",
    "        return train_loss, train_acc, pred_words, true_words\n",
    "\n",
    "    def evaluate(self):\n",
    "        assert(self.validLoader != None)\n",
    "        self.model.eval()\n",
    "        valid_loss = 0.0\n",
    "        true_words, pred_words = [], []\n",
    "        with torch.no_grad():\n",
    "            with tqdm(self.validLoader, unit=' batch') as tqdmLoader:\n",
    "                for batch_X, batch_y, X_lens, y_words in tqdmLoader:\n",
    "                    tqdmLoader.set_description(f'Validation')\n",
    "                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                    # get the logits, preds for the current batch\n",
    "                    logits, preds = self.model(batch_X, batch_y, X_lens)\n",
    "                    # ignore loss for the first time step\n",
    "                    targets = batch_y[:, 1:]; logits = logits[:, 1:, :]\n",
    "                    logits = logits.swapaxes(1, 2) # make class logits the second dimension as needed\n",
    "                    loss = self.loss_criterion(logits, targets)\n",
    "                    valid_loss += loss.item()\n",
    "                    batch_pred_words = self.tar_lang.convert_to_words(preds.cpu().numpy())\n",
    "                    tqdmLoader.set_postfix(loss=loss.item())\n",
    "                    true_words += y_words\n",
    "                    pred_words += batch_pred_words\n",
    "        valid_loss /= len(self.validLoader)\n",
    "        valid_acc = self.get_accuracy(pred_words, true_words)\n",
    "        print(f'Validation Loss = {valid_loss}; Validation Accuracy = {valid_acc * 100}')\n",
    "        return valid_loss, valid_acc, pred_words, true_words\n",
    "\n",
    "    def inference(self):\n",
    "        assert(self.testLoader != None)\n",
    "        self.model.eval()\n",
    "        pred_words, true_words = [], []\n",
    "        with torch.no_grad():\n",
    "            with tqdm(self.testLoader, unit=' batch') as tqdmLoader:\n",
    "                for batch_X, _, X_lens, y_words in tqdmLoader:\n",
    "                    tqdmLoader.set_description(f'Testing')\n",
    "                    batch_X = batch_X.to(device)\n",
    "                    # get the predicted words for the current batch\n",
    "                    batch_pred_words = self.model.inference_forward(batch_X, X_lens, 25)\n",
    "                    true_words += y_words\n",
    "                    pred_words += batch_pred_words\n",
    "        test_acc = self.get_accuracy(pred_words, true_words)\n",
    "        print(f'Test Accuracy = {test_acc * 100}')\n",
    "        return pred_words, true_words\n",
    "    \n",
    "    def beam_search_inference(self, ):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing runner\n",
    "# keep embedding small (around 32) -> important to get dense embedding\n",
    "# also, adjust learning rate reasonably\n",
    "runner = Runner(SRC_LANG, TAR_LANG, 32, 1, 1024, 'LSTM', True, 0.1, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.make_all_loaders((x_train, y_train), (x_valid, y_valid), (x_test, y_test), 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 400/400 [00:50<00:00,  7.87batch/s, loss=2.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 2.5933389937877656; Train Accuracy = 0.03515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 25.46batch/s, loss=2.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 2.1170311346650124; Validation Accuracy = 0.634765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 20.82batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 1.0009765625\n",
      "आईक्थंउउभउउउेआणषझ देशभरामध्ये\n",
      "ससअनमररररउरउतशउउझ पेशनधारियों\n",
      "टॅब!ररीइउउशशशँऔऔग अनुक्रमानुपात\n",
      "ङसजऽररघरशममऽथँनऩ वाहिन्यांसाठी\n",
      "ढसढौ्ौौञएयबछझझझझझ लोकरचनाओं\n",
      "ईयसहऽउउवेँपपतो ट्रांसक्रिप्टेज़\n",
      "ङ@ङङङँेठवजठँजजगौझ गंतिविधियों\n",
      "ओईकगौठयउउथभउउउझझझ शासनाबद्दल\n",
      "टईगउउगठररतररररररझ सर्वसंग्रह\n",
      "@ङेसॅपथँँननचओ%ःरऑ तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 400/400 [00:49<00:00,  8.04batch/s, loss=1.66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 1.7483454313874245; Train Accuracy = 1.365234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 25.32batch/s, loss=1.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.6516394838690758; Validation Accuracy = 8.0322265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 19.83batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 6.7138671875\n",
      "दिष्रामाचचा देशभरामध्ये\n",
      "प्र्व्व्यांर पेशनधारियों\n",
      "अनुत्रुुप् अनुक्रमानुपात\n",
      "वावाव्यातत वाहिन्यांसाठी\n",
      "लोखानाां लोकरचनाओं\n",
      "ट्र्रस््रोस्स ट्रांसक्रिप्टेज़\n",
      "गंत्वाव्यां गंतिविधियों\n",
      "शिद्रदुुल शासनाबद्दल\n",
      "सर्ता्गारा सर्वसंग्रह\n",
      "तुमाममामां तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 400/400 [00:49<00:00,  8.02batch/s, loss=1.11] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 1.3108171017467976; Train Accuracy = 5.705078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 23.51batch/s, loss=1.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.4206744208931923; Validation Accuracy = 13.8427734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 20.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 12.3046875\n",
      "दिध््भभा्याी देशभरामध्ये\n",
      "पक््््र्यों पेशनधारियों\n",
      "अनुक्रानंपप्र अनुक्रमानुपात\n",
      "वह्वय्यांतठी वाहिन्यांसाठी\n",
      "लोक्ाााओं लोकरचनाओं\n",
      "ट्रासस्पस्क्र ट्रांसक्रिप्टेज़\n",
      "गंविविधियों गंतिविधियों\n",
      "शश्ंदददलल शासनाबद्दल\n",
      "सर्वसंगररार सर्वसंग्रह\n",
      "तुक्ायामीकी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 400/400 [00:50<00:00,  7.99batch/s, loss=0.839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 1.0676872895658016; Train Accuracy = 10.28125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 24.34batch/s, loss=1.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.3050520941615105; Validation Accuracy = 15.966796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 20.13batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 11.4501953125\n",
      "देवारभा्यया देशभरामध्ये\n",
      "पेशार्यियों पेशनधारियों\n",
      "अनुक्रमां्द अनुक्रमानुपात\n",
      "वह्यानससाहहठी वाहिन्यांसाठी\n",
      "लोकराकाां लोकरचनाओं\n",
      "ट्रास्प्पिप्टान ट्रांसक्रिप्टेज़\n",
      "गंतिविधियों गंतिविधियों\n",
      "शससंदद्ल शासनाबद्दल\n",
      "सर्वसंगढ़ सर्वसंग्रह\n",
      "तुक्चायमीकीी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 400/400 [00:50<00:00,  7.99batch/s, loss=0.658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.8852376410365105; Train Accuracy = 13.802734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 24.62batch/s, loss=1.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.2865384854376316; Validation Accuracy = 19.7998046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 19.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 13.37890625\n",
      "देशभरांे्ये देशभरामध्ये\n",
      "पशशााधधियों पेशनधारियों\n",
      "अनुक्रमानपपात अनुक्रमानुपात\n",
      "वाह्न्यासााठी वाहिन्यांसाठी\n",
      "लोकराचाां लोकरचनाओं\n",
      "ट्रास्प्रसस्टस ट्रांसक्रिप्टेज़\n",
      "गणतिविधियों गंतिविधियों\n",
      "शससााबद्दललल शासनाबद्दल\n",
      "सर्वसंगररह सर्वसंग्रह\n",
      "पुमच्यापिका तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 400/400 [00:50<00:00,  7.94batch/s, loss=0.594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.7818373070657253; Train Accuracy = 18.478515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 24.82batch/s, loss=1.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.2697770446538925; Validation Accuracy = 21.97265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 20.39batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 18.212890625\n",
      "देशाराबाधध्येे देशभरामध्ये\n",
      "पेशाधारियोंं पेशनधारियों\n",
      "अनुक्रमापपुुतू अनुक्रमानुपात\n",
      "वाहिन्यांसाठीी वाहिन्यांसाठी\n",
      "लोकररचचाओ लोकरचनाओं\n",
      "ट्रांसप्रेप्टस ट्रांसक्रिप्टेज़\n",
      "गण्िविधियोंं गंतिविधियों\n",
      "शासानदद्दललललल शासनाबद्दल\n",
      "सर्वसंग्रह सर्वसंग्रह\n",
      "तुम्चिपाकी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 400/400 [00:50<00:00,  8.00batch/s, loss=0.594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.6630961132049561; Train Accuracy = 22.81640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 22.89batch/s, loss=1.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.2794351652264595; Validation Accuracy = 22.1435546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 20.64batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 15.7958984375\n",
      "देशभरममध्येे देशभरामध्ये\n",
      "पेशाधारियों पेशनधारियों\n",
      "अनुक्रमानुपा अनुक्रमानुपात\n",
      "वाहिन्यांसाठीीी वाहिन्यांसाठी\n",
      "लोकरचााओं लोकरचनाओं\n",
      "ट्रामस्प्रस्पेन ट्रांसक्रिप्टेज़\n",
      "गंतिविधियोंं गंतिविधियों\n",
      "शससंबबद्दलल शासनाबद्दल\n",
      "सर्वसंग्रह सर्वसंग्रह\n",
      "तुमच्यपााीीीी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 400/400 [00:50<00:00,  7.97batch/s, loss=0.402]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.5808846519142389; Train Accuracy = 27.658203125000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 24.62batch/s, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.2992070019245148; Validation Accuracy = 26.806640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 20.13batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 22.8759765625\n",
      "देशभरममध्येय देशभरामध्ये\n",
      "पेशाधारियोंं पेशनधारियों\n",
      "अनुक्रमानुपतत अनुक्रमानुपात\n",
      "वाहिन्यांसाठीीी वाहिन्यांसाठी\n",
      "लोकरचनाओं लोकरचनाओं\n",
      "ट्रांसस्रिप्टेसट ट्रांसक्रिप्टेज़\n",
      "गंतिविधियों गंतिविधियों\n",
      "शासनाबब्दललल शासनाबद्दल\n",
      "सर्वसंग्र सर्वसंग्रह\n",
      "तुमच्यापाकीीीी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 400/400 [00:50<00:00,  7.90batch/s, loss=0.374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.5141593818366528; Train Accuracy = 32.470703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 24.13batch/s, loss=1.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.3377272933721542; Validation Accuracy = 26.1474609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 20.08batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 20.7275390625\n",
      "देशभरामध्ये देशभरामध्ये\n",
      "पेशनधारियों पेशनधारियों\n",
      "अनुक्रमानुपात अनुक्रमानुपात\n",
      "वाहिन्यांसाठीीीी वाहिन्यांसाठी\n",
      "लोकरानाओं लोकरचनाओं\n",
      "ट्रांसक्रेप्सेन ट्रांसक्रिप्टेज़\n",
      "गणतिविधियोंं गंतिविधियों\n",
      "शासनाबद्दल शासनाबद्दल\n",
      "सर्वसंग्र सर्वसंग्रह\n",
      "तुमच्यापाकीी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 400/400 [00:50<00:00,  7.95batch/s, loss=0.373]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.45127433896064756; Train Accuracy = 34.099609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 32/32 [00:01<00:00, 24.32batch/s, loss=1.2] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss = 1.3311801850795746; Validation Accuracy = 27.1484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 32/32 [00:01<00:00, 20.89batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 21.19140625\n",
      "देशभरामध्ये देशभरामध्ये\n",
      "पेशनधारियों पेशनधारियों\n",
      "अनुक्रमानुततत अनुक्रमानुपात\n",
      "वाहिन्यांसाठीी वाहिन्यांसाठी\n",
      "लोकरचनाओं लोकरचनाओं\n",
      "ट्रांस्ककिक्टिस ट्रांसक्रिप्टेज़\n",
      "गततिविधियों गंतिविधियों\n",
      "शासंमद्ददल शासनाबद्दल\n",
      "सर्वसंग्रह सर्वसंग्रह\n",
      "तुमच्यापाकी तुमच्यापैकी\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    _, _, p, w = runner.train(i, 0.6)\n",
    "    runner.evaluate(); runner.inference()\n",
    "    for x, y in list(zip(p,w))[:10]:\n",
    "        print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  68%|██████▊   | 273/400 [00:34<00:15,  8.16batch/s, loss=0.641]"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    _, _, p, w = runner.train(i, 0.2)\n",
    "    runner.evaluate(); runner.inference()\n",
    "    for x, y in list(zip(p,w))[:10]:\n",
    "        print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
